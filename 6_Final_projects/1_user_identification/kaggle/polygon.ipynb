{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vp53iRU4evo-"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from scipy.sparse import csr_matrix\n",
    "\n",
    "\n",
    "\n",
    "import eli5\n",
    "import calendar\n",
    "\n",
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    # turn predictions into data frame and save as csv file\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                               \n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Входные данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wg8z9iJlhH8L"
   },
   "outputs": [],
   "source": [
    "# !unzip capstone_user_identification.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T16:27:07.998046Z",
     "iopub.status.busy": "2021-08-11T16:27:07.997654Z",
     "iopub.status.idle": "2021-08-11T16:27:08.003455Z",
     "shell.execute_reply": "2021-08-11T16:27:08.002258Z",
     "shell.execute_reply.started": "2021-08-11T16:27:07.998014Z"
    }
   },
   "outputs": [],
   "source": [
    "# from __future__ import division, print_function\n",
    "# отключим всякие предупреждения Anaconda\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T16:42:58.654209Z",
     "iopub.status.busy": "2021-08-11T16:42:58.653835Z",
     "iopub.status.idle": "2021-08-11T16:43:02.699450Z",
     "shell.execute_reply": "2021-08-11T16:43:02.698345Z",
     "shell.execute_reply.started": "2021-08-11T16:42:58.654174Z"
    },
    "id": "CTCSeq9revpC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 21), (82797, 20))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_TO_DATA = '../capstone_user_identification'\n",
    "# PATH_TO_DATA = '../input/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2'\n",
    "\n",
    "times = ['time%s' % i for i in range(1, 11)]\n",
    "# sites = ['site%s' % i for i in range(1, 11)]\n",
    "df_train = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_sessions.csv'), index_col='session_id', parse_dates=times)\n",
    "df_test = pd.read_csv(os.path.join(PATH_TO_DATA, 'test_sessions.csv'), index_col='session_id', parse_dates=times)\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T16:43:04.332917Z",
     "iopub.status.busy": "2021-08-11T16:43:04.332530Z",
     "iopub.status.idle": "2021-08-11T16:43:04.375232Z",
     "shell.execute_reply": "2021-08-11T16:43:04.373926Z",
     "shell.execute_reply.started": "2021-08-11T16:43:04.332883Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>...</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>718</td>\n",
       "      <td>2014-02-20 10:02:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>890</td>\n",
       "      <td>2014-02-22 11:19:50</td>\n",
       "      <td>941.0</td>\n",
       "      <td>2014-02-22 11:19:50</td>\n",
       "      <td>3847.0</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>941.0</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>942.0</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>3847.0</td>\n",
       "      <td>2014-02-22 11:19:52</td>\n",
       "      <td>3846.0</td>\n",
       "      <td>2014-02-22 11:19:52</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>2014-02-22 11:20:15</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>2014-02-22 11:20:16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14769</td>\n",
       "      <td>2013-12-16 16:40:17</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2013-12-16 16:40:18</td>\n",
       "      <td>14768.0</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>14769.0</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>14768.0</td>\n",
       "      <td>2013-12-16 16:40:20</td>\n",
       "      <td>14768.0</td>\n",
       "      <td>2013-12-16 16:40:21</td>\n",
       "      <td>14768.0</td>\n",
       "      <td>2013-12-16 16:40:22</td>\n",
       "      <td>14768.0</td>\n",
       "      <td>2013-12-16 16:40:24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>782</td>\n",
       "      <td>2014-03-28 10:52:12</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-03-28 10:52:42</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-03-28 10:53:12</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-03-28 10:53:42</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-03-28 10:54:12</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-03-28 10:54:42</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-03-28 10:55:12</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-03-28 10:55:42</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-03-28 10:56:12</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-03-28 10:56:42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22</td>\n",
       "      <td>2014-02-28 10:53:05</td>\n",
       "      <td>177.0</td>\n",
       "      <td>2014-02-28 10:55:22</td>\n",
       "      <td>175.0</td>\n",
       "      <td>2014-02-28 10:55:22</td>\n",
       "      <td>178.0</td>\n",
       "      <td>2014-02-28 10:55:23</td>\n",
       "      <td>177.0</td>\n",
       "      <td>2014-02-28 10:55:23</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-02-28 10:55:59</td>\n",
       "      <td>175.0</td>\n",
       "      <td>2014-02-28 10:55:59</td>\n",
       "      <td>177.0</td>\n",
       "      <td>2014-02-28 10:55:59</td>\n",
       "      <td>177.0</td>\n",
       "      <td>2014-02-28 10:57:06</td>\n",
       "      <td>178.0</td>\n",
       "      <td>2014-02-28 10:57:11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1               time1  site2               time2    site3  \\\n",
       "session_id                                                                  \n",
       "1             718 2014-02-20 10:02:45    NaN                 NaT      NaN   \n",
       "2             890 2014-02-22 11:19:50  941.0 2014-02-22 11:19:50   3847.0   \n",
       "3           14769 2013-12-16 16:40:17   39.0 2013-12-16 16:40:18  14768.0   \n",
       "4             782 2014-03-28 10:52:12  782.0 2014-03-28 10:52:42    782.0   \n",
       "5              22 2014-02-28 10:53:05  177.0 2014-02-28 10:55:22    175.0   \n",
       "\n",
       "                         time3    site4               time4  site5  \\\n",
       "session_id                                                           \n",
       "1                          NaT      NaN                 NaT    NaN   \n",
       "2          2014-02-22 11:19:51    941.0 2014-02-22 11:19:51  942.0   \n",
       "3          2013-12-16 16:40:19  14769.0 2013-12-16 16:40:19   37.0   \n",
       "4          2014-03-28 10:53:12    782.0 2014-03-28 10:53:42  782.0   \n",
       "5          2014-02-28 10:55:22    178.0 2014-02-28 10:55:23  177.0   \n",
       "\n",
       "                         time5  ...               time6    site7  \\\n",
       "session_id                      ...                                \n",
       "1                          NaT  ...                 NaT      NaN   \n",
       "2          2014-02-22 11:19:51  ... 2014-02-22 11:19:51   3847.0   \n",
       "3          2013-12-16 16:40:19  ... 2013-12-16 16:40:19  14768.0   \n",
       "4          2014-03-28 10:54:12  ... 2014-03-28 10:54:42    782.0   \n",
       "5          2014-02-28 10:55:23  ... 2014-02-28 10:55:59    175.0   \n",
       "\n",
       "                         time7    site8               time8    site9  \\\n",
       "session_id                                                             \n",
       "1                          NaT      NaN                 NaT      NaN   \n",
       "2          2014-02-22 11:19:52   3846.0 2014-02-22 11:19:52   1516.0   \n",
       "3          2013-12-16 16:40:20  14768.0 2013-12-16 16:40:21  14768.0   \n",
       "4          2014-03-28 10:55:12    782.0 2014-03-28 10:55:42    782.0   \n",
       "5          2014-02-28 10:55:59    177.0 2014-02-28 10:55:59    177.0   \n",
       "\n",
       "                         time9   site10              time10 target  \n",
       "session_id                                                          \n",
       "1                          NaT      NaN                 NaT      0  \n",
       "2          2014-02-22 11:20:15   1518.0 2014-02-22 11:20:16      0  \n",
       "3          2013-12-16 16:40:22  14768.0 2013-12-16 16:40:24      0  \n",
       "4          2014-03-28 10:56:12    782.0 2014-03-28 10:56:42      0  \n",
       "5          2014-02-28 10:57:06    178.0 2014-02-28 10:57:11      0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T16:43:05.791865Z",
     "iopub.status.busy": "2021-08-11T16:43:05.791449Z",
     "iopub.status.idle": "2021-08-11T16:43:05.821716Z",
     "shell.execute_reply": "2021-08-11T16:43:05.820556Z",
     "shell.execute_reply.started": "2021-08-11T16:43:05.791828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 253561 entries, 21669 to 204762\n",
      "Data columns (total 21 columns):\n",
      " #   Column  Non-Null Count   Dtype         \n",
      "---  ------  --------------   -----         \n",
      " 0   site1   253561 non-null  int64         \n",
      " 1   time1   253561 non-null  datetime64[ns]\n",
      " 2   site2   250098 non-null  float64       \n",
      " 3   time2   250098 non-null  datetime64[ns]\n",
      " 4   site3   246919 non-null  float64       \n",
      " 5   time3   246919 non-null  datetime64[ns]\n",
      " 6   site4   244321 non-null  float64       \n",
      " 7   time4   244321 non-null  datetime64[ns]\n",
      " 8   site5   241829 non-null  float64       \n",
      " 9   time5   241829 non-null  datetime64[ns]\n",
      " 10  site6   239495 non-null  float64       \n",
      " 11  time6   239495 non-null  datetime64[ns]\n",
      " 12  site7   237297 non-null  float64       \n",
      " 13  time7   237297 non-null  datetime64[ns]\n",
      " 14  site8   235224 non-null  float64       \n",
      " 15  time8   235224 non-null  datetime64[ns]\n",
      " 16  site9   233084 non-null  float64       \n",
      " 17  time9   233084 non-null  datetime64[ns]\n",
      " 18  site10  231052 non-null  float64       \n",
      " 19  time10  231052 non-null  datetime64[ns]\n",
      " 20  target  253561 non-null  int64         \n",
      "dtypes: datetime64[ns](10), float64(9), int64(2)\n",
      "memory usage: 42.6 MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T16:43:08.717634Z",
     "iopub.status.busy": "2021-08-11T16:43:08.717252Z",
     "iopub.status.idle": "2021-08-11T16:43:08.799957Z",
     "shell.execute_reply": "2021-08-11T16:43:08.798872Z",
     "shell.execute_reply.started": "2021-08-11T16:43:08.717598Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.sort_values(by='time1', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Словарь сайтов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T16:43:13.598841Z",
     "iopub.status.busy": "2021-08-11T16:43:13.598440Z",
     "iopub.status.idle": "2021-08-11T16:43:13.631871Z",
     "shell.execute_reply": "2021-08-11T16:43:13.631091Z",
     "shell.execute_reply.started": "2021-08-11T16:43:13.598804Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH_TO_DATA, 'site_dic.pkl'), 'rb') as f:\n",
    "    site2id  = pickle.load(f)\n",
    "id2site = {v:k for (k, v) in site2id.items()}\n",
    "id2site[0] = 'unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T16:48:25.762789Z",
     "iopub.status.busy": "2021-08-11T16:48:25.762352Z",
     "iopub.status.idle": "2021-08-11T16:48:25.767714Z",
     "shell.execute_reply": "2021-08-11T16:48:25.766925Z",
     "shell.execute_reply.started": "2021-08-11T16:48:25.762737Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T16:58:59.500226Z",
     "iopub.status.busy": "2021-08-11T16:58:59.499855Z",
     "iopub.status.idle": "2021-08-11T16:58:59.508273Z",
     "shell.execute_reply": "2021-08-11T16:58:59.507055Z",
     "shell.execute_reply.started": "2021-08-11T16:58:59.500193Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataPreparator(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Fill NaN with zero values;\n",
    "    Prepare a (Count)Vectorizer friendly 2D-list from data;\n",
    "    Site ids to names.\n",
    "    \"\"\"\n",
    "    def __init__(self, id2site):\n",
    "        super().__init__()\n",
    "        self.id2site = id2site\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        sites = ['site%s' % i for i in range(1, 11)]\n",
    "        # Convert dataframe rows to strings\n",
    "        return X[sites].fillna(0).astype('int').apply(lambda row: ' '.join([id2site[i] for i in row]), axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListPreparator(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Prepare a CountVectorizer friendly 2D-list from data.\n",
    "    \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.values.tolist()\n",
    "        # Convert dataframe rows to strings\n",
    "        return [\" \".join([str(site) for site in row]) for row in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T16:43:16.103988Z",
     "iopub.status.busy": "2021-08-11T16:43:16.103613Z",
     "iopub.status.idle": "2021-08-11T16:43:16.108305Z",
     "shell.execute_reply": "2021-08-11T16:43:16.107225Z",
     "shell.execute_reply.started": "2021-08-11T16:43:16.103957Z"
    },
    "id": "kg7jEjs4evpO"
   },
   "outputs": [],
   "source": [
    "# train_df_sites = train_df[sites].fillna(0).astype('int').apply(lambda row: ' '.join([id2site[i] for i in row]), axis=1).tolist()\n",
    "# test_df_sites = test_df[sites].fillna(0).astype('int').apply(lambda row: ' '.join([id2site[i] for i in row]), axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer_params = {\n",
    "#     'ngram_range': (1, 5),\n",
    "#     'max_features': 50000,\n",
    "#     'tokenizer': lambda s: s.split()\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T16:43:21.775136Z",
     "iopub.status.busy": "2021-08-11T16:43:21.774603Z",
     "iopub.status.idle": "2021-08-11T16:43:21.789344Z",
     "shell.execute_reply": "2021-08-11T16:43:21.788053Z",
     "shell.execute_reply.started": "2021-08-11T16:43:21.775091Z"
    }
   },
   "outputs": [],
   "source": [
    "class AttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Add new attributes to training and test set.\n",
    "    \"\"\" \n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # intraday features\n",
    "        hour = X['time1'].apply(lambda ts: ts.hour)\n",
    "        morning = ((hour >= 7) & (hour <= 11)).astype('int')\n",
    "        day = ((hour >= 12) & (hour <= 18)).astype('int')\n",
    "        evening = ((hour >= 19) & (hour <= 23)).astype('int')\n",
    "        \n",
    "        # season features\n",
    "        month = X['time1'].apply(lambda ts: ts.month)\n",
    "        summer = ((month >= 6) & (month <= 8)).astype('int')\n",
    "        \n",
    "        # day of the week features\n",
    "        weekday = X['time1'].apply(lambda ts: ts.weekday()).astype('int')\n",
    "        \n",
    "        # year features\n",
    "        year = X['time1'].apply(lambda ts: ts.year).astype('int')\n",
    "        \n",
    "        X = np.c_[morning.values, day.values, evening.values, weekday.values]\n",
    "        # summer.values, year.values\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T16:43:24.579276Z",
     "iopub.status.busy": "2021-08-11T16:43:24.578907Z",
     "iopub.status.idle": "2021-08-11T16:43:24.587021Z",
     "shell.execute_reply": "2021-08-11T16:43:24.585823Z",
     "shell.execute_reply.started": "2021-08-11T16:43:24.579246Z"
    }
   },
   "outputs": [],
   "source": [
    "class ScaledAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Add new features, that should be scaled.\n",
    "    \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        # session time features\n",
    "        times = ['time%s' % i for i in range(1, 11)]\n",
    "        # session duration: take to the power of 1/5 to normalize the distribution\n",
    "        session_duration = (X[times].max(axis=1) - X[times].min(axis=1)).astype('timedelta64[ms]').astype(int) ** 0.2\n",
    "        # number of sites visited in a session\n",
    "        number_of_sites = X[times].isnull().sum(axis=1).apply(lambda x: 10 - x)\n",
    "        # average time spent on one site during a session\n",
    "        time_per_site = (session_duration / number_of_sites) ** 0.2\n",
    "        \n",
    "        X = np.c_[session_duration.values]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['morning', 'day', 'evening', 'weekday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T16:59:33.284513Z",
     "iopub.status.busy": "2021-08-11T16:59:33.283984Z",
     "iopub.status.idle": "2021-08-11T16:59:33.290503Z",
     "shell.execute_reply": "2021-08-11T16:59:33.289585Z",
     "shell.execute_reply.started": "2021-08-11T16:59:33.284479Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer_pipeline = Pipeline([\n",
    "    (\"preparator\", DataPreparator(id2site)),\n",
    "#     (\"list_preparator\", ListPreparator()),\n",
    "    (\"vectorizer\", CountVectorizer(ngram_range=(1, 2)))\n",
    "#     (\"vectorizer\", TfidfVectorizer(ngram_range=(1, 3), max_features=50000))\n",
    "])\n",
    "\n",
    "attributes_pipeline = Pipeline([\n",
    "    (\"adder\", AttributesAdder())\n",
    "])\n",
    "\n",
    "scaled_attributes_pipeline = Pipeline([\n",
    "    (\"adder\", ScaledAttributesAdder()),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.3 s, sys: 102 ms, total: 14.4 s\n",
      "Wall time: 14.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_vectorized = vectorizer_pipeline.fit_transform(df_train)\n",
    "X_test_vectorized = vectorizer_pipeline.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train[\"target\"].astype('int').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T16:59:36.867977Z",
     "iopub.status.busy": "2021-08-11T16:59:36.867591Z",
     "iopub.status.idle": "2021-08-11T16:59:36.872794Z",
     "shell.execute_reply": "2021-08-11T16:59:36.871895Z",
     "shell.execute_reply.started": "2021-08-11T16:59:36.867941Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_pipeline = FeatureUnion(transformer_list=[\n",
    "    # ('vectorizer_pipeline', vectorizer_pipeline),\n",
    "    ('attributes_pipeline', attributes_pipeline),\n",
    "#     ('scaled_attributes_pipeline', scaled_attributes_pipeline)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T16:59:38.081253Z",
     "iopub.status.busy": "2021-08-11T16:59:38.080716Z",
     "iopub.status.idle": "2021-08-11T17:00:28.582376Z",
     "shell.execute_reply": "2021-08-11T17:00:28.581080Z",
     "shell.execute_reply.started": "2021-08-11T16:59:38.081219Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.85 s, sys: 8.82 ms, total: 5.86 s\n",
      "Wall time: 5.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_features = feature_pipeline.fit_transform(df_train)\n",
    "X_test_features = feature_pipeline.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = hstack([X_train_vectorized, X_train_features])\n",
    "X_test = hstack([X_test_vectorized, X_test_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<253561x129401 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7132042 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# duration_train = (train_df[times].max(axis=1) - train_df[times].min(axis=1))\\\n",
    "#                     .astype('timedelta64[ms]').astype(int).values.reshape(-1, 1)\n",
    "# # number_of_sites = train_df[times].isnull().sum(axis=1).apply(lambda x: 10 - x).values.reshape(-1, 1)\n",
    "# # time_per_site = (duration_train / number_of_sites)\n",
    "# # scaler.fit(np.concatenate((duration_train, time_per_site), axis=1))\n",
    "# scaler.fit(duration_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(df):\n",
    "    # intraday features\n",
    "    hour = df['time1'].apply(lambda ts: ts.hour).values\n",
    "    morning = ((hour >= 7) & (hour <= 11)).astype('int').reshape(-1, 1)\n",
    "    day = ((hour >= 12) & (hour <= 18)).astype('int').reshape(-1, 1)\n",
    "    evening = ((hour >= 19) & (hour <= 23)).astype('int').reshape(-1, 1)\n",
    "#     night = ((hour >= 0) & (hour <= 6)).astype('int').reshape(-1, 1)\n",
    "    \n",
    "    # week features\n",
    "    weekday = df.time1.apply(lambda ts: ts.weekday()).values.reshape(-1, 1)\n",
    "#     is_monday = np.isin(weekday, [0])\n",
    "#     is_wednesday = np.isin(weekday, [2])\n",
    "#     is_sunday = np.isin(weekday, [6])\n",
    "#     is_weekend = np.isin(weekday, [0, 2, 6])\n",
    "#     weekdays = pd.get_dummies(weekday.flatten()).to_numpy().reshape(7, -1, 1)\n",
    "    \n",
    "    # month features\n",
    "    month = df.time1.apply(lambda ts: ts.month).values.reshape(-1, 1)\n",
    "\n",
    "    # year features\n",
    "    year = df['time1'].apply(lambda t: 100 * t.year).values.reshape(-1, 1) / 1e5\n",
    "    year_month = df['time1'].apply(lambda t: 100 * t.year + t.month).values.reshape(-1, 1) / 1e5\n",
    "\n",
    "    # session features\n",
    "    duration = (df[times].max(axis=1) - df[times].min(axis=1))\\\n",
    "                    .astype('timedelta64[ms]').astype(int).values.reshape(-1, 1)\n",
    "#     unique_sites = df[sites].apply(lambda sites: sites.nunique(), axis=1).values.reshape(-1, 1)\n",
    "#     number_of_sites = df[times].isnull().sum(axis=1).apply(lambda x: 10 - x).values.reshape(-1, 1)\n",
    "#     time_per_site = (duration / number_of_sites)\n",
    "    duration = scaler.transform(duration)\n",
    "#     scaled = scaler.transform(np.concatenate((duration, time_per_site), axis=1)).reshape(2, -1, 1)\n",
    "    \n",
    "    # \n",
    "    feature_names =  ['morning', 'day', 'evening', 'year', 'year_month', 'weekday', 'month', \n",
    "                      'duration'] # + list(calendar.day_name)\n",
    "    result = np.array([morning, day, evening, year, year_month, weekday, month, duration]) # is_wednesday, is_monday, is_sunday\n",
    "#     result = np.concatenate((result, scaled), axis=0)\n",
    "    \n",
    "    return result, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train_features, columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hsXfmxYHevpX"
   },
   "source": [
    "### Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T17:22:57.065981Z",
     "iopub.status.busy": "2021-08-11T17:22:57.065557Z",
     "iopub.status.idle": "2021-08-11T17:22:57.070705Z",
     "shell.execute_reply": "2021-08-11T17:22:57.069806Z",
     "shell.execute_reply.started": "2021-08-11T17:22:57.065937Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, TimeSeriesSplit\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение и подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T17:22:10.498390Z",
     "iopub.status.busy": "2021-08-11T17:22:10.497952Z",
     "iopub.status.idle": "2021-08-11T17:22:10.503456Z",
     "shell.execute_reply": "2021-08-11T17:22:10.502191Z",
     "shell.execute_reply.started": "2021-08-11T17:22:10.498349Z"
    }
   },
   "outputs": [],
   "source": [
    "model = SGDClassifier(loss='log', random_state=17, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T17:22:12.282742Z",
     "iopub.status.busy": "2021-08-11T17:22:12.282391Z",
     "iopub.status.idle": "2021-08-11T17:22:12.288103Z",
     "shell.execute_reply": "2021-08-11T17:22:12.286991Z",
     "shell.execute_reply.started": "2021-08-11T17:22:12.282712Z"
    }
   },
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'penalty': ['l2'],\n",
    "    'alpha': np.linspace(3e-05, 5e-05, 11)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_split = TimeSeriesSplit(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T17:23:42.978037Z",
     "iopub.status.busy": "2021-08-11T17:23:42.977552Z",
     "iopub.status.idle": "2021-08-11T17:29:54.117952Z",
     "shell.execute_reply": "2021-08-11T17:29:54.116412Z",
     "shell.execute_reply.started": "2021-08-11T17:23:42.977997Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "search = GridSearchCV(model, param_grid=grid, cv=time_split, scoring='roc_auc')\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T17:30:37.676866Z",
     "iopub.status.busy": "2021-08-11T17:30:37.676423Z",
     "iopub.status.idle": "2021-08-11T17:30:37.683004Z",
     "shell.execute_reply": "2021-08-11T17:30:37.682195Z",
     "shell.execute_reply.started": "2021-08-11T17:30:37.676825Z"
    }
   },
   "outputs": [],
   "source": [
    "search.best_params_, search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T17:30:42.809294Z",
     "iopub.status.busy": "2021-08-11T17:30:42.808889Z",
     "iopub.status.idle": "2021-08-11T17:31:02.079784Z",
     "shell.execute_reply": "2021-08-11T17:31:02.078254Z",
     "shell.execute_reply.started": "2021-08-11T17:30:42.809257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 282 ms, sys: 80.7 ms, total: 362 ms\n",
      "Wall time: 2.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T17:32:00.268471Z",
     "iopub.status.busy": "2021-08-11T17:32:00.267935Z",
     "iopub.status.idle": "2021-08-11T17:32:00.276176Z",
     "shell.execute_reply": "2021-08-11T17:32:00.275310Z",
     "shell.execute_reply.started": "2021-08-11T17:32:00.268418Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.86023636, 0.76532219, 0.89496888, 0.98032109, 0.87101286,\n",
       "        0.89405386, 0.93894616, 0.91871378, 0.94712134, 0.96408754]),\n",
       " 0.9034784069856329,\n",
       " 0.05928347815366662)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores, cv_scores.mean(), cv_scores.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.9315069358401142,\n",
    " 0.044345068769381366 0 2 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.9180564468510812,\n",
    " 0.05889198351691508 baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.9232962337585114,\n",
    " 0.058257317090901546"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.9287111177172779,\n",
    " 0.04434090003756869 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BO52aSbSevpd",
    "outputId": "14c50521-ed54-4ba0-9f1e-b7e3956970c6"
   },
   "outputs": [],
   "source": [
    "search.best_estimator_.fit(X_train, y)\n",
    "logit_test_pred_proba = search.best_estimator_.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'feature': feature_names, 'coef': search.best_estimator_.coef_.flatten()[-len(feature_names):]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_weights(estimator=search.best_estimator_, feature_names=vectorizer.get_feature_names() + feature_names, top=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OdBll-mpevpf"
   },
   "outputs": [],
   "source": [
    "write_to_submission_file(logit_test_pred_proba[:, 1], 'result.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
