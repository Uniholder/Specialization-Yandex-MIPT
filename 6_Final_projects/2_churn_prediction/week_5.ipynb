{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYCsA0kOKzYv"
   },
   "source": [
    "# Peer-graded Assignment: Эксперименты с моделью\n",
    "\n",
    "На прошлой неделе вы поучаствовали в соревновании на kaggle и, наверняка, большинство успешно справилось с прохождением baseline, а значит пора двигаться дальше - заняться оптимизацией модели, провести серию экспериментов и построить сильное финальное решения.\n",
    "\n",
    "В этом задании вам нужно провести ряд эскпериментов, оценить качество полученных в процессе экспериментирования моделей и выбрать лучшее решение. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0D6tKw0KzY5"
   },
   "source": [
    "Задание будет оцениваться на основании загруженного jupyther notebook и развернутых ответов на поставленные вопросы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKRF_hGkPAl-"
   },
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mCP9bbN7asA5"
   },
   "outputs": [],
   "source": [
    "# !unzip data.zip\n",
    "# !pip install --upgrade scikit-learn\n",
    "# !pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T20:08:50.457684Z",
     "iopub.status.busy": "2021-09-21T20:08:50.457227Z",
     "iopub.status.idle": "2021-09-21T20:08:50.464038Z",
     "shell.execute_reply": "2021-09-21T20:08:50.463123Z",
     "shell.execute_reply.started": "2021-09-21T20:08:50.457646Z"
    },
    "id": "YEcTk6Yjep9K"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_selector as selector, ColumnTransformer\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression, SGDClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "PATH_TO_DATA = 'data'\n",
    "# PATH_TO_DATA = '../input/churn-prediction-spec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T20:06:21.536904Z",
     "iopub.status.busy": "2021-09-21T20:06:21.536696Z",
     "iopub.status.idle": "2021-09-21T20:06:22.498906Z",
     "shell.execute_reply": "2021-09-21T20:06:22.498010Z",
     "shell.execute_reply.started": "2021-09-21T20:06:21.536880Z"
    },
    "id": "2eVbRX4CequK"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(PATH_TO_DATA, 'orange_small_churn_data.train'))\n",
    "y = pd.read_csv(os.path.join(PATH_TO_DATA, 'orange_small_churn_labels.train'), header=None, squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T20:06:22.500948Z",
     "iopub.status.busy": "2021-09-21T20:06:22.500632Z",
     "iopub.status.idle": "2021-09-21T20:06:22.689511Z",
     "shell.execute_reply": "2021-09-21T20:06:22.688678Z",
     "shell.execute_reply.started": "2021-09-21T20:06:22.500919Z"
    },
    "id": "FkMY9FkuEb2O"
   },
   "outputs": [],
   "source": [
    "nan_cols = df.columns[df.isna().all()]\n",
    "df.drop(nan_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T20:06:22.803984Z",
     "iopub.status.busy": "2021-09-21T20:06:22.803680Z",
     "iopub.status.idle": "2021-09-21T20:06:22.808045Z",
     "shell.execute_reply": "2021-09-21T20:06:22.806986Z",
     "shell.execute_reply.started": "2021-09-21T20:06:22.803955Z"
    },
    "id": "xz5onAIOEb2P"
   },
   "outputs": [],
   "source": [
    "# cat_cols = df.select_dtypes(include='object').columns\n",
    "# df[cat_cols] = df[cat_cols].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T20:06:22.997374Z",
     "iopub.status.busy": "2021-09-21T20:06:22.996990Z",
     "iopub.status.idle": "2021-09-21T20:06:23.077072Z",
     "shell.execute_reply": "2021-09-21T20:06:23.076174Z",
     "shell.execute_reply.started": "2021-09-21T20:06:22.997332Z"
    },
    "id": "9lvJZytLEb2Q"
   },
   "outputs": [],
   "source": [
    "df_train, df_ho, y_train, y_valid = train_test_split(df, y, test_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T20:10:28.779254Z",
     "iopub.status.busy": "2021-09-21T20:10:28.778216Z",
     "iopub.status.idle": "2021-09-21T20:10:28.785547Z",
     "shell.execute_reply": "2021-09-21T20:10:28.784684Z",
     "shell.execute_reply.started": "2021-09-21T20:10:28.779209Z"
    },
    "id": "D4VcyYGnes59"
   },
   "outputs": [],
   "source": [
    "class DataFramer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        super().__init__()\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return pd.DataFrame(X, columns=self.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T20:12:38.956137Z",
     "iopub.status.busy": "2021-09-21T20:12:38.955469Z",
     "iopub.status.idle": "2021-09-21T20:12:38.963904Z",
     "shell.execute_reply": "2021-09-21T20:12:38.962941Z",
     "shell.execute_reply.started": "2021-09-21T20:12:38.956093Z"
    },
    "id": "OTpyeDUSevJL"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>Var11</th>\n",
       "      <th>...</th>\n",
       "      <th>Var220</th>\n",
       "      <th>Var221</th>\n",
       "      <th>Var222</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var224</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.034906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.01488</td>\n",
       "      <td>-0.020165</td>\n",
       "      <td>-0.058719</td>\n",
       "      <td>-0.309532</td>\n",
       "      <td>-1.147187</td>\n",
       "      <td>-0.035769</td>\n",
       "      <td>-0.064389</td>\n",
       "      <td>-0.031925</td>\n",
       "      <td>...</td>\n",
       "      <td>Tvpip6Z</td>\n",
       "      <td>zCkv</td>\n",
       "      <td>hHJsvbM</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>4n2X</td>\n",
       "      <td>ELof</td>\n",
       "      <td>WqMG</td>\n",
       "      <td>6fzt</td>\n",
       "      <td>F2FcTt7IdMT_v</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.034906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.01488</td>\n",
       "      <td>-0.020165</td>\n",
       "      <td>-0.058719</td>\n",
       "      <td>-0.455378</td>\n",
       "      <td>-1.147187</td>\n",
       "      <td>-0.035769</td>\n",
       "      <td>-0.064389</td>\n",
       "      <td>-0.031925</td>\n",
       "      <td>...</td>\n",
       "      <td>YTCRPlm</td>\n",
       "      <td>oslk</td>\n",
       "      <td>nXK9h3w</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>4n2X</td>\n",
       "      <td>ELof</td>\n",
       "      <td>453m</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.034906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.01488</td>\n",
       "      <td>-0.020165</td>\n",
       "      <td>-0.058719</td>\n",
       "      <td>-0.223104</td>\n",
       "      <td>0.029794</td>\n",
       "      <td>-0.035769</td>\n",
       "      <td>-0.064389</td>\n",
       "      <td>-0.031925</td>\n",
       "      <td>...</td>\n",
       "      <td>KhWT_66</td>\n",
       "      <td>oslk</td>\n",
       "      <td>0MplRwa</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>4n2X</td>\n",
       "      <td>ELof</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.034906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.01488</td>\n",
       "      <td>-0.020165</td>\n",
       "      <td>-0.058719</td>\n",
       "      <td>-0.182591</td>\n",
       "      <td>-1.147187</td>\n",
       "      <td>-0.035769</td>\n",
       "      <td>-0.064389</td>\n",
       "      <td>-0.031925</td>\n",
       "      <td>...</td>\n",
       "      <td>UF10FxM</td>\n",
       "      <td>oslk</td>\n",
       "      <td>BlJqCcD</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>4n2X</td>\n",
       "      <td>ELof</td>\n",
       "      <td>me1d</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>55YFVY9</td>\n",
       "      <td>mj86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.034906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.01488</td>\n",
       "      <td>-0.020165</td>\n",
       "      <td>-0.058719</td>\n",
       "      <td>-0.344643</td>\n",
       "      <td>-1.147187</td>\n",
       "      <td>-0.035769</td>\n",
       "      <td>-0.064389</td>\n",
       "      <td>-0.031925</td>\n",
       "      <td>...</td>\n",
       "      <td>oatfGrO</td>\n",
       "      <td>oslk</td>\n",
       "      <td>8vXEsaq</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>4n2X</td>\n",
       "      <td>ELof</td>\n",
       "      <td>7P5s</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34995</th>\n",
       "      <td>-0.034906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.01488</td>\n",
       "      <td>-0.020165</td>\n",
       "      <td>-0.058719</td>\n",
       "      <td>-0.455378</td>\n",
       "      <td>0.029794</td>\n",
       "      <td>-0.035769</td>\n",
       "      <td>-0.064389</td>\n",
       "      <td>-0.031925</td>\n",
       "      <td>...</td>\n",
       "      <td>oPZw9qN</td>\n",
       "      <td>Al6ZaUT</td>\n",
       "      <td>oIW9GgB</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>4n2X</td>\n",
       "      <td>ELof</td>\n",
       "      <td>szEZ</td>\n",
       "      <td>02N6s8f</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34996</th>\n",
       "      <td>-0.034906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.01488</td>\n",
       "      <td>-0.020165</td>\n",
       "      <td>-0.058719</td>\n",
       "      <td>1.562161</td>\n",
       "      <td>1.206775</td>\n",
       "      <td>-0.035769</td>\n",
       "      <td>-0.064389</td>\n",
       "      <td>-0.031925</td>\n",
       "      <td>...</td>\n",
       "      <td>4UxGlow</td>\n",
       "      <td>zCkv</td>\n",
       "      <td>catzS2D</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>4n2X</td>\n",
       "      <td>ELof</td>\n",
       "      <td>PM2D</td>\n",
       "      <td>ZI9m</td>\n",
       "      <td>TCU50_Yjmm6GIBZ0lL_</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34997</th>\n",
       "      <td>-0.034906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.01488</td>\n",
       "      <td>-0.020165</td>\n",
       "      <td>-0.058719</td>\n",
       "      <td>-0.104267</td>\n",
       "      <td>1.206775</td>\n",
       "      <td>-0.035769</td>\n",
       "      <td>-0.064389</td>\n",
       "      <td>-0.031925</td>\n",
       "      <td>...</td>\n",
       "      <td>KA3C5vH</td>\n",
       "      <td>oslk</td>\n",
       "      <td>m1BWuMy</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>4n2X</td>\n",
       "      <td>ELof</td>\n",
       "      <td>WqMG</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34998</th>\n",
       "      <td>-0.034906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.01488</td>\n",
       "      <td>-0.020165</td>\n",
       "      <td>-0.058719</td>\n",
       "      <td>0.157716</td>\n",
       "      <td>0.029794</td>\n",
       "      <td>-0.035769</td>\n",
       "      <td>-0.064389</td>\n",
       "      <td>-0.031925</td>\n",
       "      <td>...</td>\n",
       "      <td>J8TK3rj</td>\n",
       "      <td>oslk</td>\n",
       "      <td>6ZAHToS</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>4n2X</td>\n",
       "      <td>ELof</td>\n",
       "      <td>Qu4f</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>mj86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34999</th>\n",
       "      <td>-0.034906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.01488</td>\n",
       "      <td>-0.020165</td>\n",
       "      <td>-0.058719</td>\n",
       "      <td>2.080725</td>\n",
       "      <td>0.029794</td>\n",
       "      <td>-0.035769</td>\n",
       "      <td>-0.064389</td>\n",
       "      <td>-0.031925</td>\n",
       "      <td>...</td>\n",
       "      <td>KVXsbNi</td>\n",
       "      <td>oslk</td>\n",
       "      <td>3A8Y9dP</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>4n2X</td>\n",
       "      <td>ELof</td>\n",
       "      <td>Qu4f</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35000 rows × 212 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Var1 Var2     Var3      Var4      Var5      Var6      Var7  \\\n",
       "0     -0.034906  0.0 -0.01488 -0.020165 -0.058719 -0.309532 -1.147187   \n",
       "1     -0.034906  0.0 -0.01488 -0.020165 -0.058719 -0.455378 -1.147187   \n",
       "2     -0.034906  0.0 -0.01488 -0.020165 -0.058719 -0.223104  0.029794   \n",
       "3     -0.034906  0.0 -0.01488 -0.020165 -0.058719 -0.182591 -1.147187   \n",
       "4     -0.034906  0.0 -0.01488 -0.020165 -0.058719 -0.344643 -1.147187   \n",
       "...         ...  ...      ...       ...       ...       ...       ...   \n",
       "34995 -0.034906  0.0 -0.01488 -0.020165 -0.058719 -0.455378  0.029794   \n",
       "34996 -0.034906  0.0 -0.01488 -0.020165 -0.058719  1.562161  1.206775   \n",
       "34997 -0.034906  0.0 -0.01488 -0.020165 -0.058719 -0.104267  1.206775   \n",
       "34998 -0.034906  0.0 -0.01488 -0.020165 -0.058719  0.157716  0.029794   \n",
       "34999 -0.034906  0.0 -0.01488 -0.020165 -0.058719  2.080725  0.029794   \n",
       "\n",
       "           Var9     Var10     Var11  ...   Var220   Var221   Var222  \\\n",
       "0     -0.035769 -0.064389 -0.031925  ...  Tvpip6Z     zCkv  hHJsvbM   \n",
       "1     -0.035769 -0.064389 -0.031925  ...  YTCRPlm     oslk  nXK9h3w   \n",
       "2     -0.035769 -0.064389 -0.031925  ...  KhWT_66     oslk  0MplRwa   \n",
       "3     -0.035769 -0.064389 -0.031925  ...  UF10FxM     oslk  BlJqCcD   \n",
       "4     -0.035769 -0.064389 -0.031925  ...  oatfGrO     oslk  8vXEsaq   \n",
       "...         ...       ...       ...  ...      ...      ...      ...   \n",
       "34995 -0.035769 -0.064389 -0.031925  ...  oPZw9qN  Al6ZaUT  oIW9GgB   \n",
       "34996 -0.035769 -0.064389 -0.031925  ...  4UxGlow     zCkv  catzS2D   \n",
       "34997 -0.035769 -0.064389 -0.031925  ...  KA3C5vH     oslk  m1BWuMy   \n",
       "34998 -0.035769 -0.064389 -0.031925  ...  J8TK3rj     oslk  6ZAHToS   \n",
       "34999 -0.035769 -0.064389 -0.031925  ...  KVXsbNi     oslk  3A8Y9dP   \n",
       "\n",
       "           Var223 Var224 Var225 Var226   Var227               Var228 Var229  \n",
       "0      LM8l689qOp   4n2X   ELof   WqMG     6fzt        F2FcTt7IdMT_v   am7c  \n",
       "1      LM8l689qOp   4n2X   ELof   453m     RAYp        F2FyR07IdsN7I   am7c  \n",
       "2      LM8l689qOp   4n2X   ELof   FSa2     RAYp        F2FyR07IdsN7I   am7c  \n",
       "3      jySVZNlOJy   4n2X   ELof   me1d     RAYp              55YFVY9   mj86  \n",
       "4      LM8l689qOp   4n2X   ELof   7P5s     RAYp        F2FyR07IdsN7I   am7c  \n",
       "...           ...    ...    ...    ...      ...                  ...    ...  \n",
       "34995  LM8l689qOp   4n2X   ELof   szEZ  02N6s8f        F2FyR07IdsN7I   am7c  \n",
       "34996  LM8l689qOp   4n2X   ELof   PM2D     ZI9m  TCU50_Yjmm6GIBZ0lL_   am7c  \n",
       "34997  LM8l689qOp   4n2X   ELof   WqMG     RAYp        F2FyR07IdsN7I   am7c  \n",
       "34998  LM8l689qOp   4n2X   ELof   Qu4f     RAYp        F2FyR07IdsN7I   mj86  \n",
       "34999  LM8l689qOp   4n2X   ELof   Qu4f     RAYp        F2FyR07IdsN7I   am7c  \n",
       "\n",
       "[35000 rows x 212 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_transformer = Pipeline([\n",
    "    ('simple_imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('simple_imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#     ('ordinal_encoder', OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=-1))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, selector(dtype_exclude=\"object\")),\n",
    "    ('cat', categorical_transformer, selector(dtype_include=\"object\"))\n",
    "])\n",
    "\n",
    "preprocessor_pipeline = Pipeline([\n",
    "#     ('nan_columns_dropper', NanColumnsDropper()),\n",
    "    ('preprocessor', preprocessor),\n",
    "#     ('scaler', StandardScaler()),\n",
    "    ('to_dataframe', DataFramer(df.columns))\n",
    "])\n",
    "\n",
    "X_train = preprocessor_pipeline.fit_transform(df_train)\n",
    "X_valid = preprocessor_pipeline.transform(df_ho)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7nvlIH3kO9Pp"
   },
   "source": [
    "## Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T20:09:20.359646Z",
     "iopub.status.busy": "2021-09-21T20:09:20.358830Z",
     "iopub.status.idle": "2021-09-21T20:09:20.363812Z",
     "shell.execute_reply": "2021-09-21T20:09:20.363109Z",
     "shell.execute_reply.started": "2021-09-21T20:09:20.359580Z"
    },
    "id": "UULBZTdbfCUB"
   },
   "outputs": [],
   "source": [
    "cv = StratifiedShuffleSplit(n_splits=8, random_state=2179)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T20:13:01.355048Z",
     "iopub.status.busy": "2021-09-21T20:13:01.354721Z",
     "iopub.status.idle": "2021-09-21T20:13:01.377842Z",
     "shell.execute_reply": "2021-09-21T20:13:01.377041Z",
     "shell.execute_reply.started": "2021-09-21T20:13:01.355013Z"
    },
    "id": "TFQ-TWJOqU2w"
   },
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    max_depth=6, \n",
    "    n_estimators=100, \n",
    "    cat_features=df_train.select_dtypes(include='object').columns.to_list(),\n",
    "    random_seed=2179\n",
    ")\n",
    "\n",
    "# model = LogisticRegression(\n",
    "#     solver='liblinear',\n",
    "#     random_state=2179\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wkUX7Qmrz1Zc",
    "outputId": "4cc79b7d-9dae-4404-93ad-6cced3fa17a6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.388375\n",
      "0:\tlearn: 0.3927906\ttotal: 92.8ms\tremaining: 9.19s\n",
      "1:\tlearn: 0.3009245\ttotal: 140ms\tremaining: 6.88s\n",
      "2:\tlearn: 0.2700691\ttotal: 153ms\tremaining: 4.95s\n",
      "3:\tlearn: 0.2586001\ttotal: 183ms\tremaining: 4.39s\n",
      "4:\tlearn: 0.2540830\ttotal: 208ms\tremaining: 3.96s\n",
      "5:\tlearn: 0.2480534\ttotal: 250ms\tremaining: 3.92s\n",
      "6:\tlearn: 0.2464869\ttotal: 280ms\tremaining: 3.72s\n",
      "7:\tlearn: 0.2438972\ttotal: 307ms\tremaining: 3.53s\n",
      "8:\tlearn: 0.2424906\ttotal: 332ms\tremaining: 3.36s\n",
      "9:\tlearn: 0.2409054\ttotal: 357ms\tremaining: 3.21s\n",
      "10:\tlearn: 0.2397668\ttotal: 379ms\tremaining: 3.07s\n",
      "11:\tlearn: 0.2393237\ttotal: 402ms\tremaining: 2.94s\n",
      "12:\tlearn: 0.2392961\ttotal: 413ms\tremaining: 2.76s\n",
      "13:\tlearn: 0.2387134\ttotal: 435ms\tremaining: 2.67s\n",
      "14:\tlearn: 0.2385247\ttotal: 456ms\tremaining: 2.58s\n",
      "15:\tlearn: 0.2385005\ttotal: 465ms\tremaining: 2.44s\n",
      "16:\tlearn: 0.2380964\ttotal: 486ms\tremaining: 2.37s\n",
      "17:\tlearn: 0.2377430\ttotal: 509ms\tremaining: 2.32s\n",
      "18:\tlearn: 0.2370515\ttotal: 531ms\tremaining: 2.26s\n",
      "19:\tlearn: 0.2364595\ttotal: 554ms\tremaining: 2.22s\n",
      "20:\tlearn: 0.2343100\ttotal: 579ms\tremaining: 2.18s\n",
      "21:\tlearn: 0.2333952\ttotal: 606ms\tremaining: 2.15s\n",
      "22:\tlearn: 0.2327225\ttotal: 628ms\tremaining: 2.1s\n",
      "23:\tlearn: 0.2319460\ttotal: 653ms\tremaining: 2.07s\n",
      "24:\tlearn: 0.2318613\ttotal: 671ms\tremaining: 2.01s\n",
      "25:\tlearn: 0.2313870\ttotal: 691ms\tremaining: 1.97s\n",
      "26:\tlearn: 0.2303039\ttotal: 715ms\tremaining: 1.93s\n",
      "27:\tlearn: 0.2302661\ttotal: 736ms\tremaining: 1.89s\n",
      "28:\tlearn: 0.2302222\ttotal: 761ms\tremaining: 1.86s\n",
      "29:\tlearn: 0.2300050\ttotal: 785ms\tremaining: 1.83s\n",
      "30:\tlearn: 0.2299378\ttotal: 811ms\tremaining: 1.8s\n",
      "31:\tlearn: 0.2291588\ttotal: 842ms\tremaining: 1.79s\n",
      "32:\tlearn: 0.2286437\ttotal: 873ms\tremaining: 1.77s\n",
      "33:\tlearn: 0.2285980\ttotal: 893ms\tremaining: 1.73s\n",
      "34:\tlearn: 0.2277069\ttotal: 918ms\tremaining: 1.7s\n",
      "35:\tlearn: 0.2274054\ttotal: 941ms\tremaining: 1.67s\n",
      "36:\tlearn: 0.2270909\ttotal: 964ms\tremaining: 1.64s\n",
      "37:\tlearn: 0.2266586\ttotal: 987ms\tremaining: 1.61s\n",
      "38:\tlearn: 0.2263129\ttotal: 1.01s\tremaining: 1.58s\n",
      "39:\tlearn: 0.2262522\ttotal: 1.03s\tremaining: 1.55s\n",
      "40:\tlearn: 0.2253360\ttotal: 1.05s\tremaining: 1.52s\n",
      "41:\tlearn: 0.2252904\ttotal: 1.08s\tremaining: 1.49s\n",
      "42:\tlearn: 0.2250495\ttotal: 1.1s\tremaining: 1.46s\n",
      "43:\tlearn: 0.2244063\ttotal: 1.13s\tremaining: 1.44s\n",
      "44:\tlearn: 0.2236893\ttotal: 1.15s\tremaining: 1.41s\n",
      "45:\tlearn: 0.2236269\ttotal: 1.18s\tremaining: 1.38s\n",
      "46:\tlearn: 0.2228377\ttotal: 1.2s\tremaining: 1.35s\n",
      "47:\tlearn: 0.2225008\ttotal: 1.24s\tremaining: 1.34s\n",
      "48:\tlearn: 0.2224273\ttotal: 1.26s\tremaining: 1.31s\n",
      "49:\tlearn: 0.2220590\ttotal: 1.29s\tremaining: 1.29s\n",
      "50:\tlearn: 0.2213370\ttotal: 1.32s\tremaining: 1.27s\n",
      "51:\tlearn: 0.2213181\ttotal: 1.34s\tremaining: 1.24s\n",
      "52:\tlearn: 0.2210900\ttotal: 1.36s\tremaining: 1.21s\n",
      "53:\tlearn: 0.2206266\ttotal: 1.38s\tremaining: 1.18s\n",
      "54:\tlearn: 0.2198752\ttotal: 1.41s\tremaining: 1.15s\n",
      "55:\tlearn: 0.2192462\ttotal: 1.43s\tremaining: 1.13s\n",
      "56:\tlearn: 0.2190953\ttotal: 1.46s\tremaining: 1.1s\n",
      "57:\tlearn: 0.2181995\ttotal: 1.48s\tremaining: 1.07s\n",
      "58:\tlearn: 0.2181125\ttotal: 1.5s\tremaining: 1.04s\n",
      "59:\tlearn: 0.2177907\ttotal: 1.52s\tremaining: 1.01s\n",
      "60:\tlearn: 0.2171016\ttotal: 1.54s\tremaining: 988ms\n",
      "61:\tlearn: 0.2168740\ttotal: 1.56s\tremaining: 959ms\n",
      "62:\tlearn: 0.2164841\ttotal: 1.59s\tremaining: 932ms\n",
      "63:\tlearn: 0.2164558\ttotal: 1.61s\tremaining: 905ms\n",
      "64:\tlearn: 0.2164320\ttotal: 1.63s\tremaining: 879ms\n",
      "65:\tlearn: 0.2160030\ttotal: 1.65s\tremaining: 852ms\n",
      "66:\tlearn: 0.2154296\ttotal: 1.67s\tremaining: 825ms\n",
      "67:\tlearn: 0.2150481\ttotal: 1.7s\tremaining: 799ms\n",
      "68:\tlearn: 0.2147982\ttotal: 1.72s\tremaining: 772ms\n",
      "69:\tlearn: 0.2144089\ttotal: 1.74s\tremaining: 748ms\n",
      "70:\tlearn: 0.2140780\ttotal: 1.77s\tremaining: 723ms\n",
      "71:\tlearn: 0.2140106\ttotal: 1.79s\tremaining: 697ms\n",
      "72:\tlearn: 0.2137957\ttotal: 1.82s\tremaining: 675ms\n",
      "73:\tlearn: 0.2132891\ttotal: 1.85s\tremaining: 651ms\n",
      "74:\tlearn: 0.2130109\ttotal: 1.88s\tremaining: 626ms\n",
      "75:\tlearn: 0.2130045\ttotal: 1.9s\tremaining: 599ms\n",
      "76:\tlearn: 0.2126141\ttotal: 1.92s\tremaining: 573ms\n",
      "77:\tlearn: 0.2125146\ttotal: 1.94s\tremaining: 547ms\n",
      "78:\tlearn: 0.2116685\ttotal: 1.96s\tremaining: 521ms\n",
      "79:\tlearn: 0.2110047\ttotal: 1.98s\tremaining: 496ms\n",
      "80:\tlearn: 0.2106128\ttotal: 2s\tremaining: 470ms\n",
      "81:\tlearn: 0.2101677\ttotal: 2.03s\tremaining: 446ms\n",
      "82:\tlearn: 0.2099415\ttotal: 2.05s\tremaining: 421ms\n",
      "83:\tlearn: 0.2090064\ttotal: 2.08s\tremaining: 395ms\n",
      "84:\tlearn: 0.2086302\ttotal: 2.1s\tremaining: 370ms\n",
      "85:\tlearn: 0.2083189\ttotal: 2.12s\tremaining: 345ms\n",
      "86:\tlearn: 0.2082591\ttotal: 2.14s\tremaining: 319ms\n",
      "87:\tlearn: 0.2079487\ttotal: 2.16s\tremaining: 294ms\n",
      "88:\tlearn: 0.2076442\ttotal: 2.18s\tremaining: 269ms\n",
      "89:\tlearn: 0.2072262\ttotal: 2.2s\tremaining: 244ms\n",
      "90:\tlearn: 0.2069915\ttotal: 2.22s\tremaining: 220ms\n",
      "91:\tlearn: 0.2066329\ttotal: 2.25s\tremaining: 195ms\n",
      "92:\tlearn: 0.2061776\ttotal: 2.27s\tremaining: 171ms\n",
      "93:\tlearn: 0.2059518\ttotal: 2.29s\tremaining: 146ms\n",
      "94:\tlearn: 0.2056348\ttotal: 2.31s\tremaining: 122ms\n",
      "95:\tlearn: 0.2053933\ttotal: 2.33s\tremaining: 97.2ms\n",
      "96:\tlearn: 0.2050619\ttotal: 2.35s\tremaining: 72.8ms\n",
      "97:\tlearn: 0.2048835\ttotal: 2.37s\tremaining: 48.4ms\n",
      "98:\tlearn: 0.2046541\ttotal: 2.39s\tremaining: 24.2ms\n",
      "99:\tlearn: 0.2044121\ttotal: 2.42s\tremaining: 0us\n",
      "0.7366357888991646\n",
      "CPU times: user 24.2 s, sys: 4.13 s, total: 28.3 s\n",
      "Wall time: 3.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train)\n",
    "print(roc_auc_score(y_valid, model.predict_proba(X_valid)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T20:13:09.274020Z",
     "iopub.status.busy": "2021-09-21T20:13:09.273751Z",
     "iopub.status.idle": "2021-09-21T20:13:09.295691Z",
     "shell.execute_reply": "2021-09-21T20:13:09.294774Z",
     "shell.execute_reply.started": "2021-09-21T20:13:09.273992Z"
    },
    "id": "lncqeuybEb2c"
   },
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    max_depth=6, \n",
    "    n_estimators=100, \n",
    "    cat_features=df_train.select_dtypes(include='object').columns.to_list(),\n",
    "    logging_level='Silent',\n",
    "    random_seed=2179\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor_pipeline),\n",
    "    ('model', model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-09-21T20:14:46.364637Z",
     "iopub.status.busy": "2021-09-21T20:14:46.364289Z",
     "iopub.status.idle": "2021-09-21T20:15:37.819377Z",
     "shell.execute_reply": "2021-09-21T20:15:37.818538Z",
     "shell.execute_reply.started": "2021-09-21T20:14:46.364585Z"
    },
    "id": "E6glefHgubRT",
    "outputId": "c65b272f-261d-4428-a0ea-4827839a0b3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69302746 0.73364837 0.74197153 0.72363843 0.7210935  0.69658257\n",
      " 0.72000787 0.73028422] \n",
      " 0.7200317437490864\n",
      "CPU times: user 1.04 s, sys: 321 ms, total: 1.36 s\n",
      "Wall time: 32.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = cross_val_score(estimator=pipeline, \n",
    "                         X=df_train, \n",
    "                         y=y_train, \n",
    "                         cv=cv, \n",
    "                         n_jobs=-1, \n",
    "                         scoring='roc_auc',\n",
    "                         error_score='raise')\n",
    "print(scores, '\\n', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VL7F2u4GMzL8"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# gb_classifier = GradientBoostingClassifier(random_state=2179)\n",
    "# gb_classifier.fit(X_train, y_train)\n",
    "# print(roc_auc_score(y_valid, gb_classifier.predict_proba(X_valid)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLwAz0-IEb2e"
   },
   "source": [
    "|Модель|ho ROC AUC|cv ROC AUC|\n",
    "|-|-|-|\n",
    "|CatBoost|0.7413546342506111|0.7360205959164293|\n",
    "|LogisticRegression|0.6523649873142443|0.6725584639126306|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxG-D4arKzY-"
   },
   "source": [
    "# Инструкции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "toJqNfjrEb2f"
   },
   "source": [
    "## 1. Learning curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BI8rTRQbKzY_"
   },
   "source": [
    "1\\. Начнем с простого. Давайте оценим как много объектов действительно нужно для построения качественной модели. Для обучения доступна достаточно большая выборка и может так оказаться, что начиная с некоторого момента рост размера обучающей выборки перестает влиять на качество модели. Постройте кривые обучения, обучая модель на выборках разного размера начиная с небольшого количество объектов в обучающей выборке и постепенно наращивая её размер с некоторым шагом. Обратите внимание на `sklearn.model_selection.learning_curve`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9HC8q97nKzZC"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  learning_curve\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (13, 8)\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f1QPjeUAYUya",
    "outputId": "1d3466cb-f645-4b8c-b2d6-694a3efb3d16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.5 s, sys: 3.4 s, total: 16.9 s\n",
      "Wall time: 2min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_sizes_abs, train_scores, test_scores, fit_times, score_times = learning_curve(\n",
    "    estimator=model, # catboost\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    return_times=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_KdU6noBEb2i",
    "outputId": "5febe7df-c4e4-4e20-a24c-5ea437c85221"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_sizes_abs, train_scores.mean(axis=1), label='Train')\n",
    "plt.plot(train_sizes_abs, test_scores.mean(axis=1), label='Test')\n",
    "plt.legend()\n",
    "plt.xlabel('Размер обучающей выборки')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.title('Learning curves');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VIXnQOK4Eb2j"
   },
   "source": [
    "## 2. Balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05zahwi5KzZF"
   },
   "source": [
    "2\\. Часто несбалансированные по классам выборки приводят к различным проблемам при обучении моделей. Давайте попробуем по-разному обработать выборку, поиграть с распределением объектов по классам и сделать выводы о том, как соотношение классов влияет на качество модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZvLDTO0CEb2k"
   },
   "source": [
    "### 2.1 Веса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fioUkJaiKzZH"
   },
   "source": [
    "2.1\\. Задайте веса объектам так, чтобы соотношение классов с учетом весов объектов изменилось. Попробуйте не менее трёх различных вариантов весов. Меняются ли результаты классификации? Как это сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "LFp3dUvwEb2l",
    "outputId": "7a8e844a-8e5b-4849-d567-5d312d120ab5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08038029386343994, 12.440860215053764)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()[1] / y_train.value_counts()[-1], y_train.value_counts()[-1] / y_train.value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "wEs1BeQAEb2m"
   },
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    max_depth=6, \n",
    "    n_estimators=100, \n",
    "    cat_features=df_train.select_dtypes(include='object').columns.to_list(),\n",
    "    logging_level='Silent',\n",
    "    random_seed=2179,\n",
    "#     auto_class_weights='SqrtBalanced',\n",
    "    scale_pos_weight=0.08\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor_pipeline),\n",
    "    ('model', model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "CekY2ZSgEb2n",
    "outputId": "8034f0e8-9c4c-4992-9a60-17a3cdd8052e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7272004907017593\n",
      "CPU times: user 22.6 s, sys: 3.1 s, total: 25.7 s\n",
      "Wall time: 3.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train)\n",
    "print(roc_auc_score(y_valid, model.predict_proba(X_valid)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "T1UUdOdOEb2s",
    "outputId": "c96d7f3a-5fe4-4cf4-c08d-3ccb81790af7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73042142 0.73246617 0.76094136 0.7531529  0.74972816 0.75191952\n",
      " 0.72050214 0.73538224] \n",
      " 0.7418142361111111\n",
      "CPU times: user 781 ms, sys: 75.2 ms, total: 856 ms\n",
      "Wall time: 29.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = cross_val_score(estimator=pipeline, \n",
    "                         X=df_train, \n",
    "                         y=y_train, \n",
    "                         cv=cv, \n",
    "                         n_jobs=-1, \n",
    "                         scoring='roc_auc')\n",
    "print(scores, '\\n', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNElNPj8Eb2t"
   },
   "source": [
    "|parameter|hold out ROC AUC|cv ROC AUC|\n",
    "|-|-|-|\n",
    "|no|0.7413546342506111|0.7360205959164293|\n",
    "|auto_class_weights='Balanced'|0.7064833272924973|0.7140111585944919|\n",
    "|auto_class_weights='SqrtBalanced'|0.7036220620626203|0.7237520773979107|\n",
    "|scale_pos_weight=12|0.6873611769407347|0.7186974715099714|\n",
    "|scale_pos_weight=0.08|0.7272004907017593|0.7418142361111111|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vO44wjI7Eb2t"
   },
   "source": [
    "### 2.2 Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7jpQTm0KzZL"
   },
   "source": [
    "2.2\\. Примените к выборке технологию undersampling: для этого нужно убрать из обучения некоторое количество объектов большего класса таким образом, чтобы соотношение классов изменилось. Попробуйте не менее трёх различных вариантов undersampling (варианты могут отличаться как по количество отфильтрованных объектов, так и по принципу выборка объектов для отсеивания из выборки). Меняются ли результаты классификации? Как это сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "ix7PimRKEb2v"
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "cCvfZZvbKzZO"
   },
   "outputs": [],
   "source": [
    "THRESH = 75\n",
    "\n",
    "df_train_n_churn = df_train[y_train == -1]\n",
    "df_train_undersampling = pd.concat([df_train_n_churn.dropna(thresh=THRESH), df_train[y_train == 1]])\n",
    "\n",
    "X_train_undersampling = preprocessor_pipeline.fit_transform(df_train_undersampling)\n",
    "X_train_undersampling = pd.DataFrame(X_train_undersampling, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "Th1gy6UrEb2x"
   },
   "outputs": [],
   "source": [
    "SIZE = 20000\n",
    "\n",
    "sample = random.sample(df_train_n_churn.index.to_list(), SIZE)\n",
    "\n",
    "df_train_undersampling = pd.concat([df_train_n_churn.loc[sample], df_train[y_train == 1]])\n",
    "\n",
    "X_train_undersampling = preprocessor_pipeline.fit_transform(df_train_undersampling)\n",
    "X_train_undersampling = pd.DataFrame(X_train_undersampling, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "AgT3IQVoEb2x"
   },
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    max_depth=6, \n",
    "    n_estimators=100, \n",
    "    cat_features=df_train.select_dtypes(include='object').columns.to_list(),\n",
    "    logging_level='Silent',\n",
    "    random_seed=2179,\n",
    "    scale_pos_weight=0.08\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-dATr1DAEb2y",
    "outputId": "cca9e7e4-5559-4a09-b9fd-74003d26c72d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7255624947723534\n",
      "CPU times: user 17.7 s, sys: 2.06 s, total: 19.8 s\n",
      "Wall time: 2.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_undersampling, y_train[df_train_undersampling.index])\n",
    "print(roc_auc_score(y_valid, model.predict_proba(X_valid)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNcn1RysEb23"
   },
   "source": [
    "|threshold|ho ROC AUC|\n",
    "|-|-|\n",
    "|70|0.6625795183130269|\n",
    "|73|0.6477388105129134|\n",
    "|75|0.6170019911524985|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CtlfhPZ_Eb27"
   },
   "source": [
    "|size|ho ROC AUC|\n",
    "|-|-|\n",
    "|32395|0.7316768083010381|\n",
    "|30000|0.735964349773701|\n",
    "|25000|0.7286578423992341|\n",
    "|20000|0.7255624947723534|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGmHBxMtEb28"
   },
   "source": [
    "## 3. Признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PpXmo0lkKzZP"
   },
   "source": [
    "3\\. Теперь перейдем к работе с признаками. Ранее вы реализовали несколько стратегий для обработки пропущенных значений. Сравните эти стратегии между собой с помощью оценки качества моделей кросс-валидации, построенных на датасетах с использованием различных стратегий. Как обработка пропущенных значений сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "-lkcMROFEb29"
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "cDCCU40_Eb2-"
   },
   "outputs": [],
   "source": [
    "cv = StratifiedShuffleSplit(n_splits=8, random_state=2179)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIOD6L63Eb2-"
   },
   "source": [
    "Стратегия 1: замена на самое частое значение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "X-lw_MLjKzZQ"
   },
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline([\n",
    "    ('simple_imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('simple_imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    # ('ordinal_encoder', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, selector(dtype_exclude=\"object\")),\n",
    "    ('cat', categorical_transformer, selector(dtype_include=\"object\"))\n",
    "])\n",
    "\n",
    "preprocessor_pipeline = Pipeline([\n",
    "#     ('nan_columns_dropper', NanColumnsDropper()),\n",
    "    ('preprocessor', preprocessor),\n",
    "    # ('scaler', StandardScaler())\n",
    "    ('to_dataframe', DataFramer(df.columns))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ei4uJwjXEb3A",
    "outputId": "bd3440e5-fcec-43c7-a88d-d9a4fc27d3b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 603 ms, sys: 279 ms, total: 882 ms\n",
      "Wall time: 894 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>Var11</th>\n",
       "      <th>...</th>\n",
       "      <th>Var220</th>\n",
       "      <th>Var221</th>\n",
       "      <th>Var222</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var224</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.43775</td>\n",
       "      <td>-1.144028</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>fgzCsbI</td>\n",
       "      <td>Al6ZaUT</td>\n",
       "      <td>p2s4IB0</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>4n2X</td>\n",
       "      <td>ELof</td>\n",
       "      <td>xb3V</td>\n",
       "      <td>02N6s8f</td>\n",
       "      <td>R4y5gQQWY8OodqDV</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.124917</td>\n",
       "      <td>0.034159</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9WbYE38</td>\n",
       "      <td>oslk</td>\n",
       "      <td>ZI_Qhib</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>4n2X</td>\n",
       "      <td>ELof</td>\n",
       "      <td>7FJQ</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>TCU50_Yjmm6GIBZ0lL_</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.603077</td>\n",
       "      <td>0.034159</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>CWefR8o</td>\n",
       "      <td>oslk</td>\n",
       "      <td>_8WEKx8</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>4n2X</td>\n",
       "      <td>ELof</td>\n",
       "      <td>Qu4f</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.496224</td>\n",
       "      <td>-1.144028</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>FonmS85</td>\n",
       "      <td>oslk</td>\n",
       "      <td>PC0a_vf</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>4n2X</td>\n",
       "      <td>ELof</td>\n",
       "      <td>5Acm</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>55YFVY9</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.078138</td>\n",
       "      <td>1.212347</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>kM3Ojel</td>\n",
       "      <td>oslk</td>\n",
       "      <td>20HE4Qn</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>4n2X</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>Xa3G</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.157078</td>\n",
       "      <td>-1.144028</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Dw7YjZW</td>\n",
       "      <td>oslk</td>\n",
       "      <td>oCzEVaf</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>4n2X</td>\n",
       "      <td>ELof</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375031</td>\n",
       "      <td>0.034159</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8_rAQQR</td>\n",
       "      <td>oslk</td>\n",
       "      <td>rT1IXkw</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>4n2X</td>\n",
       "      <td>ELof</td>\n",
       "      <td>szEZ</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.203856</td>\n",
       "      <td>0.034159</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>fabfGrO</td>\n",
       "      <td>oslk</td>\n",
       "      <td>TT_zF_Q</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>4n2X</td>\n",
       "      <td>ELof</td>\n",
       "      <td>szEZ</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34998</th>\n",
       "      <td>0.995947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.030477</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>U8I9Iah</td>\n",
       "      <td>oslk</td>\n",
       "      <td>5i2a5gA</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>4n2X</td>\n",
       "      <td>ELof</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.045978</td>\n",
       "      <td>0.034159</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>EFki84d</td>\n",
       "      <td>zCkv</td>\n",
       "      <td>T5HWwhx</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>4n2X</td>\n",
       "      <td>ELof</td>\n",
       "      <td>Qcbd</td>\n",
       "      <td>6fzt</td>\n",
       "      <td>Zy3gnGM</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35000 rows × 212 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Var1 Var2 Var3 Var4 Var5      Var6      Var7       Var9 Var10  \\\n",
       "0           0.0  0.0 -0.0  0.0  0.0  -0.43775 -1.144028       -0.0  -0.0   \n",
       "1           0.0  0.0 -0.0  0.0  0.0 -0.124917  0.034159       -0.0  -0.0   \n",
       "2           0.0  0.0 -0.0  0.0  0.0  0.603077  0.034159       -0.0  -0.0   \n",
       "3           0.0  0.0 -0.0  0.0  0.0 -0.496224 -1.144028       -0.0  -0.0   \n",
       "4           0.0  0.0 -0.0  0.0  0.0 -0.078138  1.212347       -0.0  -0.0   \n",
       "...         ...  ...  ...  ...  ...       ...       ...        ...   ...   \n",
       "34995       0.0  0.0 -0.0  0.0  0.0 -0.157078 -1.144028       -0.0  -0.0   \n",
       "34996       0.0  0.0 -0.0  0.0  0.0  0.375031  0.034159       -0.0  -0.0   \n",
       "34997       0.0  0.0 -0.0  0.0  0.0 -0.203856  0.034159       -0.0  -0.0   \n",
       "34998  0.995947  0.0 -0.0  0.0  0.0       0.0       0.0  13.030477  -0.0   \n",
       "34999       0.0  0.0 -0.0  0.0  0.0 -0.045978  0.034159       -0.0  -0.0   \n",
       "\n",
       "      Var11  ...   Var220   Var221   Var222      Var223 Var224 Var225 Var226  \\\n",
       "0       0.0  ...  fgzCsbI  Al6ZaUT  p2s4IB0  LM8l689qOp   4n2X   ELof   xb3V   \n",
       "1       0.0  ...  9WbYE38     oslk  ZI_Qhib  LM8l689qOp   4n2X   ELof   7FJQ   \n",
       "2       0.0  ...  CWefR8o     oslk  _8WEKx8  LM8l689qOp   4n2X   ELof   Qu4f   \n",
       "3       0.0  ...  FonmS85     oslk  PC0a_vf  LM8l689qOp   4n2X   ELof   5Acm   \n",
       "4       0.0  ...  kM3Ojel     oslk  20HE4Qn  LM8l689qOp   4n2X   kG3k   Xa3G   \n",
       "...     ...  ...      ...      ...      ...         ...    ...    ...    ...   \n",
       "34995   0.0  ...  Dw7YjZW     oslk  oCzEVaf  LM8l689qOp   4n2X   ELof   FSa2   \n",
       "34996   0.0  ...  8_rAQQR     oslk  rT1IXkw  LM8l689qOp   4n2X   ELof   szEZ   \n",
       "34997   0.0  ...  fabfGrO     oslk  TT_zF_Q  LM8l689qOp   4n2X   ELof   szEZ   \n",
       "34998   0.0  ...  U8I9Iah     oslk  5i2a5gA  LM8l689qOp   4n2X   ELof   FSa2   \n",
       "34999   0.0  ...  EFki84d     zCkv  T5HWwhx  LM8l689qOp   4n2X   ELof   Qcbd   \n",
       "\n",
       "        Var227               Var228 Var229  \n",
       "0      02N6s8f     R4y5gQQWY8OodqDV   am7c  \n",
       "1         RAYp  TCU50_Yjmm6GIBZ0lL_   am7c  \n",
       "2         RAYp        F2FyR07IdsN7I   am7c  \n",
       "3         RAYp              55YFVY9   am7c  \n",
       "4         RAYp        F2FyR07IdsN7I   am7c  \n",
       "...        ...                  ...    ...  \n",
       "34995     RAYp        F2FyR07IdsN7I   am7c  \n",
       "34996     RAYp        F2FyR07IdsN7I   am7c  \n",
       "34997     RAYp        F2FyR07IdsN7I   am7c  \n",
       "34998     RAYp        F2FyR07IdsN7I   am7c  \n",
       "34999     6fzt              Zy3gnGM   am7c  \n",
       "\n",
       "[35000 rows x 212 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "X_train = preprocessor_pipeline.fit_transform(df_train)\n",
    "X_valid = preprocessor_pipeline.transform(df_ho)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "jn--yiatEb3A"
   },
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    max_depth=6, \n",
    "    n_estimators=100, \n",
    "    cat_features=df_train.select_dtypes(include='object').columns.to_list(),\n",
    "    logging_level='Silent',\n",
    "    random_seed=2179\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor_pipeline),\n",
    "    ('model', model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iBFzgUYIEb3B",
    "outputId": "e0f160f4-0d0c-487d-9de0-a69fae5207d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.727643098112471\n",
      "CPU times: user 27 s, sys: 3.23 s, total: 30.2 s\n",
      "Wall time: 3.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train)\n",
    "print(roc_auc_score(y_valid, model.predict_proba(X_valid)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KPWwj1MqEb3B",
    "outputId": "a60d4c35-1e63-40a8-d779-ca4a48119d76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73711538 0.72188272 0.77223765 0.75138295 0.75252849 0.76614435\n",
      " 0.72148267 0.74505461] \n",
      " 0.7459786028015195\n",
      "CPU times: user 787 ms, sys: 69 ms, total: 856 ms\n",
      "Wall time: 34.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = cross_val_score(estimator=pipeline, \n",
    "                         X=df_train, \n",
    "                         y=y_train, \n",
    "                         cv=cv, \n",
    "                         n_jobs=-1, \n",
    "                         scoring='roc_auc', \n",
    "                         error_score='raise')\n",
    "print(scores, '\\n', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7x9zhAI4Eb3B"
   },
   "source": [
    "|method num|method cat|ho ROC AUC|cv ROC AUC|\n",
    "|-|-|-|-|\n",
    "|most_frequent|most_frequent|0.7413546342506111|0.7360205959164293|\n",
    "|mean|most_frequent|0.727643098112471|0.7459786028015195|\n",
    "|median|most_frequent|0.7243560701108726|0.7375290835707502|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Categorical encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXq_YeBHKzZR"
   },
   "source": [
    "4\\. Также вы уже реализовали несколько стратегий для обработки категориальных признаков. Сравните эти стратегии между собой с помощью оценки качества моделей по кросс-валидации, построенных на датасетах с использованием различных стратегий. Как обработка категориальных признаков сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrequencyEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        dict_ = {}\n",
    "        self.cat_cols = X.select_dtypes('object').columns\n",
    "        for col in self.cat_cols:\n",
    "            dict_[col] = X.groupby(col).size() / len(X)\n",
    "        self.fe = dict_\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X[self.cat_cols] = X[self.cat_cols].apply(lambda col: col.map(self.fe[col.name]))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iZChsUajKzZS",
    "outputId": "f9efbc95-9e86-4e7f-9f8a-7e59d6869ef0",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot use mean strategy with non-numeric data:\ncould not convert string to float: 'r__I'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    563\u001b[0m                 \u001b[0;34m\"data given during fit.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             )\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mXs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_transform_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[0;34m(self, X, y, func, fitted)\u001b[0m\n\u001b[1;32m    433\u001b[0m             self._iter(fitted=fitted, replace_strings=True))\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             return Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m    436\u001b[0m                 delayed(func)(\n\u001b[1;32m    437\u001b[0m                     \u001b[0mtransformer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_transform_one\u001b[0;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_transform_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m     \u001b[0;31m# if we have a weight for this transformer, multiply output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/impute/_base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_fit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0mstatistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/impute/_base.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(self, X, in_fit)\u001b[0m\n\u001b[1;32m    258\u001b[0m                 new_ve = ValueError(\"Cannot use {} strategy with non-numeric \"\n\u001b[1;32m    259\u001b[0m                                     \"data:\\n{}\".format(self.strategy, ve))\n\u001b[0;32m--> 260\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mnew_ve\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot use mean strategy with non-numeric data:\ncould not convert string to float: 'r__I'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "numeric_transformer = Pipeline([\n",
    "    ('simple_imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('simple_imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#     ('ordinal_encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)),\n",
    "#     ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore')),\n",
    "    ('to_dataframe', DataFramer(df.columns)),\n",
    "    ('frequency_encoder', FrequencyEncoder())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, selector(dtype_exclude=\"object\")),\n",
    "    ('cat', categorical_transformer, selector(dtype_include=\"object\"))\n",
    "])\n",
    "\n",
    "preprocessor_pipeline = Pipeline([\n",
    "#     ('nan_columns_dropper', NanColumnsDropper()),\n",
    "    ('preprocessor', preprocessor),\n",
    "#     ('scaler', StandardScaler()),\n",
    "    ('to_dataframe', DataFramer(df.columns))\n",
    "])\n",
    "\n",
    "X_train = preprocessor_pipeline.fit_transform(df_train)\n",
    "X_valid = preprocessor_pipeline.transform(df_ho)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FrequencyEncoder' object has no attribute 'cat_cols'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-154-4a10989baf13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreprocessor_pipeline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'preprocessor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformers_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'FrequencyEncoder' object has no attribute 'cat_cols'"
     ]
    }
   ],
   "source": [
    "preprocessor_pipeline['preprocessor'].transformers_[1][1][2].cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = {}\n",
    "for col in tmp.columns:\n",
    "    dict_[col] = tmp.groupby(col).size() / len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Var191': Var191\n",
       " r__I    1.0\n",
       " dtype: float64,\n",
       " 'Var192': Var192\n",
       " 0G9vyxdMWg    0.000029\n",
       " 0kQTmBU3gb    0.000029\n",
       " 0kQqrQsiZt    0.000029\n",
       " 0vimfo8zhV    0.006743\n",
       " 1GdOj17ejg    0.005771\n",
       "                 ...   \n",
       " zKnr4RXktW    0.007257\n",
       " zKnrjIPxRp    0.000029\n",
       " zcROj17IEC    0.006000\n",
       " zcROj1KVEH    0.001543\n",
       " zcRZptzip9    0.004829\n",
       " Length: 346, dtype: float64,\n",
       " 'Var193': Var193\n",
       " 2Knk1KF                                     0.145314\n",
       " 2wnefc9ISdLjfQoAYBI                         0.000114\n",
       " 5QKIjwyXr4MCZTEp7uAkS8PtBLcn                0.001286\n",
       " 8kO9LslBGNXoLvWEuN6tPuN59TdYxfL9Sm6oU       0.000171\n",
       " 9U2tunPAje3TwfLLUQxzM3dC1ghn                0.000057\n",
       " AERks4l                                     0.043943\n",
       " B2T7ZTgOX7xpBPBD28SLvVWgBkc13Sm0a3tk2       0.000029\n",
       " BrRu5UxtiQY9TTJ8ABKpfS                      0.000400\n",
       " ByQdnLRlFnny2k4AJzG                         0.001771\n",
       " DH86UFkz9LK6My0ezUgZx96oI                   0.000029\n",
       " Fveq5yuDUj6drSMiZO3mXe                      0.000429\n",
       " GpoBynXzkxADI7bZBtqvX2IPV5t7o2QCPE          0.001029\n",
       " J71wxZB6Jn0CR82XoyV                         0.000057\n",
       " JXVE                                        0.000657\n",
       " KjAW4rq3iyvu8XwKkyQ2_svIATjM3B5             0.000029\n",
       " LrdVolaSGUfkVeWC                            0.003686\n",
       " LrdZy8QqgUfkVShG                            0.008886\n",
       " MJdP52puUMWhmExsNdlkGDbNTFln2Eg             0.001743\n",
       " ND3t9Yro9U                                  0.001857\n",
       " NMCEYavk0YOlqn2jHeEDjP0xsdXeAZGnZDN0NOfV    0.000971\n",
       " NRCqczK                                     0.001114\n",
       " OpDzzQJ                                     0.000029\n",
       " PomAbFU                                     0.001971\n",
       " QG5U1Qs9mF3805lxYz2cGPnrm                   0.000029\n",
       " RO12                                        0.719771\n",
       " SrUWsbENd7prk                               0.000029\n",
       " TW8dXluYzKpktZjuY8kSPBaZa                   0.003200\n",
       " X1rJx42ksaRn3qcM                            0.000286\n",
       " X2uI6IsGev                                  0.000886\n",
       " _7J0OGNN8s6gFzbM                            0.001229\n",
       " bYmQ4nc                                     0.002086\n",
       " e6CkoqApVR                                  0.010486\n",
       " eSGpMwS8zSGgq_trOpckZ5                      0.008971\n",
       " g62hiBSaKg                                  0.011857\n",
       " gGvYE2F8JHtPlbzkGbl                         0.000029\n",
       " hnq7pOcHWLojUTXc7HQutLwmffdy                0.000029\n",
       " iKEouAWeUBYR3fQ5tZmt_bDPIn6qT7tIGHs8L       0.000286\n",
       " msph93375qXRfw6hcMceRRIDdmHq8wn             0.000143\n",
       " onTuEhrJJQy_H3IHkZku5AFczhYGqxJ890          0.005200\n",
       " qqimvRzsp8ZZdKRPgzLg68joSn_k                0.002029\n",
       " rEUOq2QD1qfkRr6qpua                         0.009114\n",
       " snf9xe6PBwBZ8lKzhEz                         0.000629\n",
       " ues7INAmyjdS1vDd0YL9jU                      0.000657\n",
       " vuPfq6YcbX                                  0.003143\n",
       " w9ygS99Qp_                                  0.003486\n",
       " wvnt2iBhAPeGqIKaFUxJc6ca3IYp                0.000029\n",
       " yaM_UXtlxCFW5NHTcftwou7BmXcP9VITdHAto       0.000057\n",
       " z3s4Ji522ZB1FauqOOqbkl                      0.000229\n",
       " zPhCMhkz9XiOF7LgT9VfJZ3yI                   0.000543\n",
       " dtype: float64,\n",
       " 'Var194': Var194\n",
       " CTUH    0.000800\n",
       " SEuy    0.995629\n",
       " lvza    0.003571\n",
       " dtype: float64,\n",
       " 'Var195': Var195\n",
       " ArtjQZ8ftr3NB       0.000343\n",
       " ArtjQZQO1r9fC       0.000114\n",
       " ArtjQZmIvr94p       0.000343\n",
       " BNjsq81k1tWAYigY    0.000114\n",
       " CiJDdr4TQ0rGERIS    0.011086\n",
       " CiJsoa4TQ0rGHlMp    0.000057\n",
       " CuXi4je             0.003314\n",
       " F1JQrEL             0.000114\n",
       " I9xt3GBDKUbd8       0.000371\n",
       " I9xt3GDRhUK7p       0.001114\n",
       " I9xt3GMcxUnBZ       0.000514\n",
       " I9xt3Gi01UK7p       0.000029\n",
       " LfvqpCtLOY          0.017486\n",
       " TnJpfvsJgF          0.000114\n",
       " V10_0kx3ZF2we       0.000029\n",
       " XMIgoIlPqx          0.000029\n",
       " ZZBPiZh             0.000057\n",
       " b_3Q                0.001457\n",
       " bsZtYxFjzA          0.000171\n",
       " ev6I                0.003571\n",
       " hiMqnEM7VgIk4JUu    0.000343\n",
       " lSbpiq1             0.000229\n",
       " taul                0.959000\n",
       " dtype: float64,\n",
       " 'Var196': Var196\n",
       " 1K8T    0.991400\n",
       " JA1C    0.000429\n",
       " mKeq    0.000029\n",
       " z3mO    0.008143\n",
       " dtype: float64,\n",
       " 'Var197': Var197\n",
       " 0LaQ    0.002286\n",
       " 0WHw    0.004143\n",
       " 0Xwj    0.094200\n",
       " 0Y9G    0.008286\n",
       " 0YIT    0.000829\n",
       "           ...   \n",
       " yxYT    0.000200\n",
       " z32l    0.018829\n",
       " z72i    0.000029\n",
       " z8at    0.000829\n",
       " zcPU    0.000257\n",
       " Length: 218, dtype: float64,\n",
       " 'Var198': Var198\n",
       " 02s4XMm    0.000029\n",
       " 04quqyB    0.000029\n",
       " 05vx4QS    0.000057\n",
       " 067eUDx    0.000057\n",
       " 06X7E9Z    0.000029\n",
       "              ...   \n",
       " zmM4q6X    0.000029\n",
       " zmMFZH4    0.000029\n",
       " zmMlkJq    0.000629\n",
       " zuN95OD    0.000029\n",
       " zv8CdSD    0.000057\n",
       " Length: 3676, dtype: float64,\n",
       " 'Var199': Var199\n",
       " 00J8E9a             0.000429\n",
       " 01r9QwR9mpRnm       0.000029\n",
       " 01rpPS3KgPnu7       0.000086\n",
       " 03dnv4GDcc          0.000029\n",
       " 0DCFSyZnMW          0.000029\n",
       "                       ...   \n",
       " zvpdulkaWOQlA       0.000029\n",
       " zxagMIH             0.000029\n",
       " zxarPvc             0.000743\n",
       " zyR5BuUrkb8I9Lth    0.000057\n",
       " zzcv6yg4s3UGv       0.000029\n",
       " Length: 4060, dtype: float64,\n",
       " 'Var200': Var200\n",
       " 01kFO1M    0.000029\n",
       " 01kHI_O    0.000029\n",
       " 01kLdzZ    0.000029\n",
       " 01kV_s5    0.000029\n",
       " 02hHpkL    0.000086\n",
       "              ...   \n",
       " zxbh2BE    0.000029\n",
       " zxbiUTi    0.000057\n",
       " zxbpFqe    0.000029\n",
       " zxbyzIV    0.000057\n",
       " zzQ9udm    0.000057\n",
       " Length: 12104, dtype: float64,\n",
       " 'Var201': Var201\n",
       " 6dX3    0.000143\n",
       " smXZ    0.999857\n",
       " dtype: float64,\n",
       " 'Var202': Var202\n",
       " 0062    0.000371\n",
       " 00AD    0.000114\n",
       " 0152    0.000057\n",
       " 01Id    0.000086\n",
       " 01br    0.000057\n",
       "           ...   \n",
       " zxsN    0.000371\n",
       " zyO0    0.000114\n",
       " zylC    0.000800\n",
       " zz34    0.000086\n",
       " zzpZ    0.000029\n",
       " Length: 5411, dtype: float64,\n",
       " 'Var203': Var203\n",
       " 9_Y1    0.908943\n",
       " F3hy    0.028914\n",
       " HLqf    0.062086\n",
       " dgxZ    0.000057\n",
       " dtype: float64,\n",
       " 'Var204': Var204\n",
       " 000J    0.009971\n",
       " 0A_v    0.010971\n",
       " 15m3    0.021543\n",
       " 1Bp0    0.009600\n",
       " 3NyY    0.002800\n",
       "           ...   \n",
       " xQ2A    0.016971\n",
       " xSqs    0.011000\n",
       " yrDU    0.008229\n",
       " z5Ry    0.020914\n",
       " zfpA    0.007400\n",
       " Length: 100, dtype: float64,\n",
       " 'Var205': Var205\n",
       " 09_Q       0.230743\n",
       " VpdQ       0.680057\n",
       " sJzTlal    0.089200\n",
       " dtype: float64,\n",
       " 'Var206': Var206\n",
       " 409L       0.000171\n",
       " 43pnToF    0.030600\n",
       " 69fI       0.004457\n",
       " 6JmL       0.021914\n",
       " CoYW       0.005114\n",
       " G_zk       0.002343\n",
       " IYzP       0.457029\n",
       " TIA9       0.002029\n",
       " Tkho       0.013114\n",
       " giwq       0.008000\n",
       " hAFG       0.056886\n",
       " haYg       0.057286\n",
       " hzlB       0.008371\n",
       " itlM       0.008029\n",
       " kxE9       0.030400\n",
       " lVqb       0.015771\n",
       " oZyB       0.004943\n",
       " sYC_       0.079000\n",
       " wMei       0.035486\n",
       " y6dw       0.029914\n",
       " zm5i       0.129143\n",
       " dtype: float64,\n",
       " 'Var207': Var207\n",
       " 0MCPoln                      0.000314\n",
       " 15TtzZrRt2                   0.000486\n",
       " 5iay                         0.001629\n",
       " 6C53VA1kCv                   0.002400\n",
       " 7M47J5GA0pTYIFxg5uy          0.137800\n",
       " DHn_WUyBhW_whjA88g9bvA64_    0.070371\n",
       " EBKcR3s6B22tD6gC36gm6S       0.000600\n",
       " GjJ35utlTa_GNSvxxpb9ju       0.021629\n",
       " Kxdu                         0.038771\n",
       " NKv3VA1BpP                   0.025171\n",
       " me75fM6ugJ                   0.700600\n",
       " o0ZZAVSQ32YuE                0.000029\n",
       " tMBVJkA0xJMEATvl4ht          0.000029\n",
       " wXfldy7                      0.000171\n",
       " dtype: float64,\n",
       " 'Var208': Var208\n",
       " kIsH    0.924457\n",
       " sBgB    0.075543\n",
       " dtype: float64,\n",
       " 'Var210': Var210\n",
       " 3av_    0.001371\n",
       " 7A3j    0.009743\n",
       " DM_V    0.003086\n",
       " g5HH    0.029943\n",
       " oT7d    0.003571\n",
       " uKAI    0.952286\n",
       " dtype: float64,\n",
       " 'Var211': Var211\n",
       " L84s    0.805257\n",
       " Mtgm    0.194743\n",
       " dtype: float64,\n",
       " 'Var212': Var212\n",
       " 0ufvj1SlEJJXp       0.000057\n",
       " 1OjWUjS             0.000029\n",
       " 1YxyYTLbzthWO       0.002571\n",
       " 3DU5ycSrJHCaC       0.000314\n",
       " 3vzwTT0wY25GE       0.000029\n",
       "                       ...   \n",
       " tbewxY_YSo          0.000971\n",
       " tw2KJMQ4CHDUN7hS    0.000086\n",
       " uOTgAWJ2It          0.000143\n",
       " zD9lk3UmVL          0.000114\n",
       " zz1zifk             0.000029\n",
       " Length: 77, dtype: float64,\n",
       " 'Var213': Var213\n",
       " KdSa    1.0\n",
       " dtype: float64,\n",
       " 'Var214': Var214\n",
       " 00TArgI    0.000029\n",
       " 00TG9XT    0.000029\n",
       " 00TGf3V    0.000029\n",
       " 00TGzAM    0.000029\n",
       " 00TNuBd    0.000057\n",
       "              ...   \n",
       " zzbGa54    0.000057\n",
       " zzfHvGh    0.000171\n",
       " zzfLM_S    0.000029\n",
       " zzfUfAI    0.000086\n",
       " zzfo6HG    0.000029\n",
       " Length: 12104, dtype: float64,\n",
       " 'Var215': Var215\n",
       " eGzu    1.0\n",
       " dtype: float64,\n",
       " 'Var216': Var216\n",
       " 11p0d_e    0.000029\n",
       " 11p3sk4    0.000286\n",
       " 11p43BP    0.000029\n",
       " 11p49H7    0.000029\n",
       " 11p4cJh    0.000086\n",
       "              ...   \n",
       " y5Fxyzk    0.000057\n",
       " y5FyPEY    0.000029\n",
       " y5FyWqR    0.000057\n",
       " y5Fy_2X    0.000029\n",
       " y5Fzn1t    0.000029\n",
       " Length: 1717, dtype: float64,\n",
       " 'Var217': Var217\n",
       " 00Lk    0.000029\n",
       " 00Pj    0.000029\n",
       " 010O    0.000029\n",
       " 015k    0.000057\n",
       " 01Xr    0.000057\n",
       "           ...   \n",
       " zxZB    0.000029\n",
       " zyQA    0.000029\n",
       " zyxo    0.000029\n",
       " zz4X    0.000029\n",
       " zzQV    0.000057\n",
       " Length: 11593, dtype: float64,\n",
       " 'Var218': Var218\n",
       " UYBR    0.481114\n",
       " cJvF    0.518886\n",
       " dtype: float64,\n",
       " 'Var219': Var219\n",
       " 49W0rUY       0.000057\n",
       " 49W9HeL       0.000057\n",
       " 6krWwfF       0.000057\n",
       " AT1N          0.000057\n",
       " AU8KzzF       0.000086\n",
       " AU8OvAe       0.000143\n",
       " AU8_WTd       0.011486\n",
       " AU8ltHK       0.000200\n",
       " AU8pNoi       0.022543\n",
       " FQHxeR8       0.000171\n",
       " FqMWi1g       0.000543\n",
       " FzaX          0.909743\n",
       " HEoH          0.000029\n",
       " JdAM          0.000171\n",
       " Lmli          0.005257\n",
       " OFWH          0.016629\n",
       " kgEg          0.000029\n",
       " lkwAXjv       0.000057\n",
       " qxDb          0.022143\n",
       " tdJW_Pm       0.001371\n",
       " wwPEXoilkr    0.008714\n",
       " ylgWTXl       0.000457\n",
       " dtype: float64,\n",
       " 'Var220': Var220\n",
       " 07m8iqZ    0.001257\n",
       " 07mCabK    0.000029\n",
       " 07mQFkJ    0.000457\n",
       " 07mRngW    0.000029\n",
       " 07mVy8V    0.000086\n",
       "              ...   \n",
       " zqsvdH_    0.001086\n",
       " zxm38SL    0.000171\n",
       " zxm6hzI    0.000371\n",
       " zxmVxx9    0.000086\n",
       " zxmyH3X    0.000057\n",
       " Length: 3676, dtype: float64,\n",
       " 'Var221': Var221\n",
       " Al6ZaUT    0.033857\n",
       " JIiEFBU    0.002829\n",
       " QKW8DRm    0.032857\n",
       " d0EEeJi    0.061286\n",
       " oslk       0.739314\n",
       " z4pH       0.005314\n",
       " zCkv       0.124543\n",
       " dtype: float64,\n",
       " 'Var222': Var222\n",
       " 00ARusu    0.001029\n",
       " 00AYONy    0.000029\n",
       " 00AhP4J    0.000057\n",
       " 017QQMs    0.000543\n",
       " 017QhSV    0.000029\n",
       "              ...   \n",
       " zvSA17J    0.000029\n",
       " zvSNyBY    0.000029\n",
       " zvSO_7b    0.000429\n",
       " zwFAGfT    0.000514\n",
       " zwFqcLF    0.000057\n",
       " Length: 3676, dtype: float64,\n",
       " 'Var223': Var223\n",
       " LM8l689qOp    0.836457\n",
       " M_8D          0.040629\n",
       " bCPvVye       0.002971\n",
       " jySVZNlOJy    0.119943\n",
       " dtype: float64,\n",
       " 'Var224': Var224\n",
       " 4n2X    1.0\n",
       " dtype: float64,\n",
       " 'Var225': Var225\n",
       " ELof    0.745571\n",
       " kG3k    0.207257\n",
       " xG3x    0.047171\n",
       " dtype: float64,\n",
       " 'Var226': Var226\n",
       " 3Cy4    0.025886\n",
       " 453m    0.044029\n",
       " 5Acm    0.043314\n",
       " 7FJQ    0.011000\n",
       " 7P5s    0.055914\n",
       " 7aLG    0.022486\n",
       " Aoh3    0.052686\n",
       " FSa2    0.161229\n",
       " PM2D    0.028086\n",
       " Qcbd    0.041371\n",
       " Qu4f    0.098600\n",
       " TNEC    0.021171\n",
       " WqMG    0.084857\n",
       " Xa3G    0.028229\n",
       " fKCe    0.052657\n",
       " kwS7    0.022714\n",
       " me1d    0.024257\n",
       " rgKb    0.026914\n",
       " szEZ    0.058914\n",
       " uWr3    0.026486\n",
       " wX53    0.019171\n",
       " w_Ub    0.007543\n",
       " xb3V    0.042486\n",
       " dtype: float64,\n",
       " 'Var227': Var227\n",
       " 02N6s8f    0.047771\n",
       " 6fzt       0.068457\n",
       " RAYp       0.702257\n",
       " ZI9m       0.122857\n",
       " nIGXDli    0.045657\n",
       " nIGjgSB    0.000486\n",
       " vJ_w8kB    0.012514\n",
       " dtype: float64,\n",
       " 'Var228': Var228\n",
       " 0pzBWGkV3fbsGZN52DH          0.002400\n",
       " 4rd_                         0.001857\n",
       " 55YFVY9                      0.086114\n",
       " 5oZS                         0.000257\n",
       " 6nxx00q6gnIF8ePJ3P3AEfZ1N    0.000486\n",
       " 9VmiOykV3fbsAg65e4w          0.000029\n",
       " DU8B                         0.000571\n",
       " F2FcTt7IdMT_v                0.017086\n",
       " F2FyR07IdsN7I                0.655000\n",
       " JnGLH58smNxIYcGK39k          0.000800\n",
       " NoEd                         0.009229\n",
       " R4y5gQQWY8OodqDV             0.032229\n",
       " RjBDiL8f9CQYc21fICscNNpj6    0.000143\n",
       " SbOd7O8ky1wGNxp0Arj0Xs       0.014943\n",
       " TCU50_Yjmm6GIBZ0lL_          0.025400\n",
       " VjDE                         0.006629\n",
       " WfJ2BB2SFSqauljlfOB          0.005457\n",
       " WfJYmPMksSqa1pajvfG          0.003343\n",
       " ZeaF                         0.001171\n",
       " Zy3gnGM                      0.018971\n",
       " _cTCyH95OE93jSkoIBT          0.000143\n",
       " am14IcfM7tWLrUmRT52KtA       0.008714\n",
       " b9qbUNk0dML_Mvi2             0.000800\n",
       " d0LtHjWeaXyArdN4sxU_saXqH    0.000200\n",
       " ib5G6X1eUxUn6                0.052600\n",
       " iyHGyLCEkQ                   0.024971\n",
       " n1OBWGkV3fbsHR75taC          0.000029\n",
       " r_7E                         0.000486\n",
       " xwM2aC7IdeMC0                0.029943\n",
       " dtype: float64,\n",
       " 'Var229': Var229\n",
       " am7c    0.804371\n",
       " mj86    0.194086\n",
       " oJmt    0.000771\n",
       " sk2h    0.000771\n",
       " dtype: float64}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var191</th>\n",
       "      <th>Var192</th>\n",
       "      <th>Var193</th>\n",
       "      <th>Var194</th>\n",
       "      <th>Var195</th>\n",
       "      <th>Var196</th>\n",
       "      <th>Var197</th>\n",
       "      <th>Var198</th>\n",
       "      <th>Var199</th>\n",
       "      <th>Var200</th>\n",
       "      <th>...</th>\n",
       "      <th>Var220</th>\n",
       "      <th>Var221</th>\n",
       "      <th>Var222</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var224</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004143</td>\n",
       "      <td>0.010486</td>\n",
       "      <td>0.995629</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>0.094200</td>\n",
       "      <td>0.015314</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.512286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015314</td>\n",
       "      <td>0.124543</td>\n",
       "      <td>0.015314</td>\n",
       "      <td>0.836457</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745571</td>\n",
       "      <td>0.084857</td>\n",
       "      <td>0.068457</td>\n",
       "      <td>0.017086</td>\n",
       "      <td>0.804371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.719771</td>\n",
       "      <td>0.995629</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>0.005143</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.512286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>0.739314</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>0.836457</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745571</td>\n",
       "      <td>0.044029</td>\n",
       "      <td>0.702257</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.804371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003314</td>\n",
       "      <td>0.719771</td>\n",
       "      <td>0.995629</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>0.094200</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.004486</td>\n",
       "      <td>0.512286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.739314</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.836457</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745571</td>\n",
       "      <td>0.161229</td>\n",
       "      <td>0.702257</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.804371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.145314</td>\n",
       "      <td>0.995629</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>0.088886</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>0.003229</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>0.739314</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>0.119943</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745571</td>\n",
       "      <td>0.024257</td>\n",
       "      <td>0.702257</td>\n",
       "      <td>0.086114</td>\n",
       "      <td>0.194086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003743</td>\n",
       "      <td>0.719771</td>\n",
       "      <td>0.995629</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>0.088886</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>0.512286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.739314</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.836457</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745571</td>\n",
       "      <td>0.055914</td>\n",
       "      <td>0.702257</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.804371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006657</td>\n",
       "      <td>0.719771</td>\n",
       "      <td>0.995629</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>0.007857</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.002343</td>\n",
       "      <td>0.512286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.033857</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.836457</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745571</td>\n",
       "      <td>0.058914</td>\n",
       "      <td>0.047771</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.804371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003714</td>\n",
       "      <td>0.145314</td>\n",
       "      <td>0.995629</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>0.039857</td>\n",
       "      <td>0.089000</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089000</td>\n",
       "      <td>0.124543</td>\n",
       "      <td>0.089000</td>\n",
       "      <td>0.836457</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745571</td>\n",
       "      <td>0.028086</td>\n",
       "      <td>0.122857</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>0.804371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005057</td>\n",
       "      <td>0.719771</td>\n",
       "      <td>0.995629</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.013114</td>\n",
       "      <td>0.512286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.739314</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.836457</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745571</td>\n",
       "      <td>0.084857</td>\n",
       "      <td>0.702257</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.804371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.719771</td>\n",
       "      <td>0.995629</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>0.003857</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.739314</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.836457</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745571</td>\n",
       "      <td>0.098600</td>\n",
       "      <td>0.702257</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.194086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.719771</td>\n",
       "      <td>0.995629</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>0.094200</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.018914</td>\n",
       "      <td>0.512286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.739314</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.836457</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745571</td>\n",
       "      <td>0.098600</td>\n",
       "      <td>0.702257</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.804371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35000 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Var191    Var192    Var193    Var194  Var195  Var196    Var197  \\\n",
       "0         1.0  0.004143  0.010486  0.995629   0.959  0.9914  0.094200   \n",
       "1         1.0  0.006029  0.719771  0.995629   0.959  0.9914  0.005143   \n",
       "2         1.0  0.003314  0.719771  0.995629   0.959  0.9914  0.094200   \n",
       "3         1.0  0.001257  0.145314  0.995629   0.959  0.9914  0.088886   \n",
       "4         1.0  0.003743  0.719771  0.995629   0.959  0.9914  0.088886   \n",
       "...       ...       ...       ...       ...     ...     ...       ...   \n",
       "34995     1.0  0.006657  0.719771  0.995629   0.959  0.9914  0.007857   \n",
       "34996     1.0  0.003714  0.145314  0.995629   0.959  0.9914  0.039857   \n",
       "34997     1.0  0.005057  0.719771  0.995629   0.959  0.9914  0.000314   \n",
       "34998     1.0  0.006000  0.719771  0.995629   0.959  0.9914  0.003857   \n",
       "34999     1.0  0.006000  0.719771  0.995629   0.959  0.9914  0.094200   \n",
       "\n",
       "         Var198    Var199    Var200  ...    Var220    Var221    Var222  \\\n",
       "0      0.015314  0.000143  0.512286  ...  0.015314  0.124543  0.015314   \n",
       "1      0.002057  0.000343  0.512286  ...  0.002057  0.739314  0.002057   \n",
       "2      0.000371  0.004486  0.512286  ...  0.000371  0.739314  0.000371   \n",
       "3      0.001171  0.003229  0.000286  ...  0.001171  0.739314  0.001171   \n",
       "4      0.001000  0.001229  0.512286  ...  0.001000  0.739314  0.001000   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "34995  0.000057  0.002343  0.512286  ...  0.000057  0.033857  0.000057   \n",
       "34996  0.089000  0.009200  0.000029  ...  0.089000  0.124543  0.089000   \n",
       "34997  0.000371  0.013114  0.512286  ...  0.000371  0.739314  0.000371   \n",
       "34998  0.000857  0.001000  0.000057  ...  0.000857  0.739314  0.000857   \n",
       "34999  0.000343  0.018914  0.512286  ...  0.000343  0.739314  0.000343   \n",
       "\n",
       "         Var223  Var224    Var225    Var226    Var227    Var228    Var229  \n",
       "0      0.836457     1.0  0.745571  0.084857  0.068457  0.017086  0.804371  \n",
       "1      0.836457     1.0  0.745571  0.044029  0.702257  0.655000  0.804371  \n",
       "2      0.836457     1.0  0.745571  0.161229  0.702257  0.655000  0.804371  \n",
       "3      0.119943     1.0  0.745571  0.024257  0.702257  0.086114  0.194086  \n",
       "4      0.836457     1.0  0.745571  0.055914  0.702257  0.655000  0.804371  \n",
       "...         ...     ...       ...       ...       ...       ...       ...  \n",
       "34995  0.836457     1.0  0.745571  0.058914  0.047771  0.655000  0.804371  \n",
       "34996  0.836457     1.0  0.745571  0.028086  0.122857  0.025400  0.804371  \n",
       "34997  0.836457     1.0  0.745571  0.084857  0.702257  0.655000  0.804371  \n",
       "34998  0.836457     1.0  0.745571  0.098600  0.702257  0.655000  0.194086  \n",
       "34999  0.836457     1.0  0.745571  0.098600  0.702257  0.655000  0.804371  \n",
       "\n",
       "[35000 rows x 38 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.apply(lambda col: col.map(dict_[col.name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var191</th>\n",
       "      <th>Var192</th>\n",
       "      <th>Var193</th>\n",
       "      <th>Var194</th>\n",
       "      <th>Var195</th>\n",
       "      <th>Var196</th>\n",
       "      <th>Var197</th>\n",
       "      <th>Var198</th>\n",
       "      <th>Var199</th>\n",
       "      <th>Var200</th>\n",
       "      <th>...</th>\n",
       "      <th>Var220</th>\n",
       "      <th>Var221</th>\n",
       "      <th>Var222</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var224</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000J</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0062</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00AD</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00ARusu</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00AYONy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzfHvGh</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzfLM_S</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzfUfAI</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzfo6HG</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzpZ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58996 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Var191  Var192  Var193  Var194  Var195  Var196  Var197  Var198  \\\n",
       "000J        NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "0062        NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "00AD        NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "00ARusu     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "00AYONy     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "...         ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "zzfHvGh     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "zzfLM_S     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "zzfUfAI     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "zzfo6HG     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "zzpZ        NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "         Var199  Var200  ...  Var220  Var221    Var222  Var223  Var224  \\\n",
       "000J        NaN     NaN  ...     NaN     NaN       NaN     NaN     NaN   \n",
       "0062        NaN     NaN  ...     NaN     NaN       NaN     NaN     NaN   \n",
       "00AD        NaN     NaN  ...     NaN     NaN       NaN     NaN     NaN   \n",
       "00ARusu     NaN     NaN  ...     NaN     NaN  0.001029     NaN     NaN   \n",
       "00AYONy     NaN     NaN  ...     NaN     NaN  0.000029     NaN     NaN   \n",
       "...         ...     ...  ...     ...     ...       ...     ...     ...   \n",
       "zzfHvGh     NaN     NaN  ...     NaN     NaN       NaN     NaN     NaN   \n",
       "zzfLM_S     NaN     NaN  ...     NaN     NaN       NaN     NaN     NaN   \n",
       "zzfUfAI     NaN     NaN  ...     NaN     NaN       NaN     NaN     NaN   \n",
       "zzfo6HG     NaN     NaN  ...     NaN     NaN       NaN     NaN     NaN   \n",
       "zzpZ        NaN     NaN  ...     NaN     NaN       NaN     NaN     NaN   \n",
       "\n",
       "         Var225  Var226  Var227  Var228  Var229  \n",
       "000J        NaN     NaN     NaN     NaN     NaN  \n",
       "0062        NaN     NaN     NaN     NaN     NaN  \n",
       "00AD        NaN     NaN     NaN     NaN     NaN  \n",
       "00ARusu     NaN     NaN     NaN     NaN     NaN  \n",
       "00AYONy     NaN     NaN     NaN     NaN     NaN  \n",
       "...         ...     ...     ...     ...     ...  \n",
       "zzfHvGh     NaN     NaN     NaN     NaN     NaN  \n",
       "zzfLM_S     NaN     NaN     NaN     NaN     NaN  \n",
       "zzfUfAI     NaN     NaN     NaN     NaN     NaN  \n",
       "zzfo6HG     NaN     NaN     NaN     NaN     NaN  \n",
       "zzpZ        NaN     NaN     NaN     NaN     NaN  \n",
       "\n",
       "[58996 rows x 38 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.apply(lambda col: tmp.groupby(col.name).size() / len(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var191</th>\n",
       "      <th>Var192</th>\n",
       "      <th>Var193</th>\n",
       "      <th>Var194</th>\n",
       "      <th>Var195</th>\n",
       "      <th>Var196</th>\n",
       "      <th>Var197</th>\n",
       "      <th>Var198</th>\n",
       "      <th>Var199</th>\n",
       "      <th>Var200</th>\n",
       "      <th>...</th>\n",
       "      <th>Var220</th>\n",
       "      <th>Var221</th>\n",
       "      <th>Var222</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var224</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004143</td>\n",
       "      <td>0.010486</td>\n",
       "      <td>0.995629</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>0.094200</td>\n",
       "      <td>0.015314</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.512286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015314</td>\n",
       "      <td>0.124543</td>\n",
       "      <td>0.015314</td>\n",
       "      <td>0.836457</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745571</td>\n",
       "      <td>0.084857</td>\n",
       "      <td>0.068457</td>\n",
       "      <td>0.017086</td>\n",
       "      <td>0.804371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.719771</td>\n",
       "      <td>0.995629</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>0.005143</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.512286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>0.739314</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>0.836457</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745571</td>\n",
       "      <td>0.044029</td>\n",
       "      <td>0.702257</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.804371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003314</td>\n",
       "      <td>0.719771</td>\n",
       "      <td>0.995629</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>0.094200</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.004486</td>\n",
       "      <td>0.512286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.739314</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.836457</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745571</td>\n",
       "      <td>0.161229</td>\n",
       "      <td>0.702257</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.804371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.145314</td>\n",
       "      <td>0.995629</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>0.088886</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>0.003229</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>0.739314</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>0.119943</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745571</td>\n",
       "      <td>0.024257</td>\n",
       "      <td>0.702257</td>\n",
       "      <td>0.086114</td>\n",
       "      <td>0.194086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003743</td>\n",
       "      <td>0.719771</td>\n",
       "      <td>0.995629</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>0.088886</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>0.512286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.739314</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.836457</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745571</td>\n",
       "      <td>0.055914</td>\n",
       "      <td>0.702257</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.804371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006657</td>\n",
       "      <td>0.719771</td>\n",
       "      <td>0.995629</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>0.007857</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.002343</td>\n",
       "      <td>0.512286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.033857</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.836457</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745571</td>\n",
       "      <td>0.058914</td>\n",
       "      <td>0.047771</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.804371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003714</td>\n",
       "      <td>0.145314</td>\n",
       "      <td>0.995629</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>0.039857</td>\n",
       "      <td>0.089000</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089000</td>\n",
       "      <td>0.124543</td>\n",
       "      <td>0.089000</td>\n",
       "      <td>0.836457</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745571</td>\n",
       "      <td>0.028086</td>\n",
       "      <td>0.122857</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>0.804371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005057</td>\n",
       "      <td>0.719771</td>\n",
       "      <td>0.995629</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.013114</td>\n",
       "      <td>0.512286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.739314</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.836457</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745571</td>\n",
       "      <td>0.084857</td>\n",
       "      <td>0.702257</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.804371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.719771</td>\n",
       "      <td>0.995629</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>0.003857</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.739314</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.836457</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745571</td>\n",
       "      <td>0.098600</td>\n",
       "      <td>0.702257</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.194086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.719771</td>\n",
       "      <td>0.995629</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>0.094200</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.018914</td>\n",
       "      <td>0.512286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.739314</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.836457</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745571</td>\n",
       "      <td>0.098600</td>\n",
       "      <td>0.702257</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.804371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35000 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Var191    Var192    Var193    Var194  Var195  Var196    Var197  \\\n",
       "0         1.0  0.004143  0.010486  0.995629   0.959  0.9914  0.094200   \n",
       "1         1.0  0.006029  0.719771  0.995629   0.959  0.9914  0.005143   \n",
       "2         1.0  0.003314  0.719771  0.995629   0.959  0.9914  0.094200   \n",
       "3         1.0  0.001257  0.145314  0.995629   0.959  0.9914  0.088886   \n",
       "4         1.0  0.003743  0.719771  0.995629   0.959  0.9914  0.088886   \n",
       "...       ...       ...       ...       ...     ...     ...       ...   \n",
       "34995     1.0  0.006657  0.719771  0.995629   0.959  0.9914  0.007857   \n",
       "34996     1.0  0.003714  0.145314  0.995629   0.959  0.9914  0.039857   \n",
       "34997     1.0  0.005057  0.719771  0.995629   0.959  0.9914  0.000314   \n",
       "34998     1.0  0.006000  0.719771  0.995629   0.959  0.9914  0.003857   \n",
       "34999     1.0  0.006000  0.719771  0.995629   0.959  0.9914  0.094200   \n",
       "\n",
       "         Var198    Var199    Var200  ...    Var220    Var221    Var222  \\\n",
       "0      0.015314  0.000143  0.512286  ...  0.015314  0.124543  0.015314   \n",
       "1      0.002057  0.000343  0.512286  ...  0.002057  0.739314  0.002057   \n",
       "2      0.000371  0.004486  0.512286  ...  0.000371  0.739314  0.000371   \n",
       "3      0.001171  0.003229  0.000286  ...  0.001171  0.739314  0.001171   \n",
       "4      0.001000  0.001229  0.512286  ...  0.001000  0.739314  0.001000   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "34995  0.000057  0.002343  0.512286  ...  0.000057  0.033857  0.000057   \n",
       "34996  0.089000  0.009200  0.000029  ...  0.089000  0.124543  0.089000   \n",
       "34997  0.000371  0.013114  0.512286  ...  0.000371  0.739314  0.000371   \n",
       "34998  0.000857  0.001000  0.000057  ...  0.000857  0.739314  0.000857   \n",
       "34999  0.000343  0.018914  0.512286  ...  0.000343  0.739314  0.000343   \n",
       "\n",
       "         Var223  Var224    Var225    Var226    Var227    Var228    Var229  \n",
       "0      0.836457     1.0  0.745571  0.084857  0.068457  0.017086  0.804371  \n",
       "1      0.836457     1.0  0.745571  0.044029  0.702257  0.655000  0.804371  \n",
       "2      0.836457     1.0  0.745571  0.161229  0.702257  0.655000  0.804371  \n",
       "3      0.119943     1.0  0.745571  0.024257  0.702257  0.086114  0.194086  \n",
       "4      0.836457     1.0  0.745571  0.055914  0.702257  0.655000  0.804371  \n",
       "...         ...     ...       ...       ...       ...       ...       ...  \n",
       "34995  0.836457     1.0  0.745571  0.058914  0.047771  0.655000  0.804371  \n",
       "34996  0.836457     1.0  0.745571  0.028086  0.122857  0.025400  0.804371  \n",
       "34997  0.836457     1.0  0.745571  0.084857  0.702257  0.655000  0.804371  \n",
       "34998  0.836457     1.0  0.745571  0.098600  0.702257  0.655000  0.194086  \n",
       "34999  0.836457     1.0  0.745571  0.098600  0.702257  0.655000  0.804371  \n",
       "\n",
       "[35000 rows x 38 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.apply(lambda col: col.map(tmp.groupby(col.name).size() / len(tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "qu-Njvj4A8lQ"
   },
   "outputs": [],
   "source": [
    "# model = CatBoostClassifier(\n",
    "#     max_depth=6, \n",
    "#     n_estimators=100, \n",
    "#     cat_features=df_train.select_dtypes(include='object').columns.to_list(),\n",
    "#     logging_level='Silent',\n",
    "#     one_hot_max_size=2\n",
    "# )\n",
    "\n",
    "model = LogisticRegression(random_state=2179)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor_pipeline),\n",
    "    ('model', model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "40LBan-04-Jp",
    "outputId": "4b5d6d76-3449-4a5a-f994-5a6c014d1c67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6261950605679286\n",
      "CPU times: user 25.3 s, sys: 371 ms, total: 25.7 s\n",
      "Wall time: 3.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train)\n",
    "print(roc_auc_score(y_valid, model.predict_proba(X_valid)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OvLrFZCZ8KYh",
    "outputId": "db10cf22-84bc-4b3d-a37e-826aee247038"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64029016 0.62795218 0.64354941 0.63887095 0.62355544 0.60999628\n",
      " 0.60809731 0.62896355] \n",
      " 0.627659408314434\n",
      "CPU times: user 2.29 s, sys: 141 ms, total: 2.43 s\n",
      "Wall time: 8.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = cross_val_score(estimator=pipeline, \n",
    "                         X=df_train, \n",
    "                         y=y_train, \n",
    "                         cv=cv, \n",
    "                         n_jobs=-1, \n",
    "                         scoring='roc_auc', \n",
    "                         error_score='raise')\n",
    "print(scores, '\\n', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gG0w76w8T8c"
   },
   "source": [
    "|model|method|ho ROC AUC|cv ROC AUC|\n",
    "|-|-|-|-|\n",
    "|CatBoostClassifier|one_hot_max_size=2|0.7495747310914603|0.7238648100650569|\n",
    "|CatBoostClassifier|one_hot_max_size=100|0.7473075616276679|0.7253192386638854|\n",
    "|LogisticRegression|OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)|0.6807580466653527|0.6522513838530051|\n",
    "|LogisticRegression|OneHotEncoder(handle_unknown='ignore')|0.6261950605679286|0.627659408314434|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Отбор признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgllaTH0KzZS"
   },
   "source": [
    "5\\. Все ли признаки оказались полезными для построения моделей? Проведите процедуру отбора признаков, попробуйте разные варианты отбора (обратите внимание на модуль `sklearn.feature_selection`). Например, можно выбрасывать случайные признаки или строить отбор на основе l1-регуляризации - отфильтровать из обучения признаки, которые получат нулевой вес при построении регрессии с l1-регуляризацией (`sklearn.linear_model.Lasso`). И всегда можно придумать что-то своё=) Попробуйте как минимум 2 различные стратегии, сравните результаты. Помог ли отбор признаков улучшить качество модели? Поясните свой ответ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XhrX-ArnKzZT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3tLHNRd9KzZU"
   },
   "source": [
    "6\\. Подберите оптимальные параметры модели. Обратите внимание, что в зависимости от того, как вы обработали исходные данные, сделали ли балансировку классов, сколько объектов оставили в обучающей выборке и др. оптимальные значения параметров могут меняться. Возьмите наилучшее из ваших решений на текущий момент и проведите процедуру подбора параметров модели (обратите внимание на `sklearn.model_selection.GridSearchCV`) Как подбор параметров повлиял на качество модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0gcfVYqUKzZU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Важность признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfWjw-84KzZU"
   },
   "source": [
    "7\\. Предложите методику оценки того, какие признаки внесли наибольший вклад в модель (например, это могут быть веса в случае регрессии, а также большое количество моделей реализуют метод `feature_importances_` - оценка важности признаков). На основе предложенной методики проанализируйте, какие признаки внесли больший вклад в модель, а какие меньший?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "joAXy4F5KzZV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgmC3MqdKzZW"
   },
   "source": [
    "8\\. Напоследок давайте посмотрим на объекты. На каких объектах достигается наибольшая ошибка классификации? Есть ли межу этими объектами что-то общее? Видны ли какие-либо закономерности? Предположите, почему наибольшая ошибка достигается именно на этих объектах. В данном случае \"наибольшую\" ошибку можно понимать как отнесение объекта с чужому классу с большой долей уверенности (с высокой вероятностью)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MSxOGkwzKzZX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VIHIQplXKzZX"
   },
   "source": [
    "9\\. По итогам проведенных экспериментов постройте финальную решение - модель с наилучшим качеством. Укажите, какие преобразования данных, параметры и пр. вы выбрали для построения финальной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZanMUE0HKzZY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfTnxjoAKzZZ"
   },
   "source": [
    "10\\. Подумайте, можно ли еще улучшить модель? Что для этого можно сделать? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WGoHs_21KzZa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GzxOFiRRJeeQ"
   },
   "source": [
    "# Тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DrEBp-MVJgdI"
   },
   "outputs": [],
   "source": [
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='result', index_label=\"id\"):\n",
    "    # turn predictions into data frame and save as csv file\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(0, predicted_labels.shape[0]),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wABzZLrwJyda"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(os.path.join(PATH_TO_DATA, 'orange_small_churn_test_data.csv'), index_col=0)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AP32k4fEJz-a"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X_test = preprocessor_pipeline.fit_transform(df_test)\n",
    "X_test = pd.DataFrame(X_test, columns=preprocessor_pipeline['nan_columns_dropper'].cols)#.astype('int')\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DMhwi9GaJ2Xr"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# catboost_classifier.fit(X_train_all, y)\n",
    "prediction = catboost_classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WQYtnW0YKAlk"
   },
   "outputs": [],
   "source": [
    "write_to_submission_file(prediction[:, 1], 'result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bzGTRZudKGku"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "week_5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
