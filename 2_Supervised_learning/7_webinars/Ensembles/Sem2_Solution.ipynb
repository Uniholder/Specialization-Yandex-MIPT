{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Композиции и ансамблирование. Введение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача.\n",
    "Имеется 3 классификатора:\n",
    "$$C_1, C_2, C_3$$\n",
    "$$Accuracy_{(C_1)} = 0.7$$ \n",
    "$$Accuracy_{(C_2)} = 0.7$$ \n",
    "$$Accuracy_{(C_1)} = 0.7$$\n",
    "\n",
    "Составим классификатор $C_4$ по принципу голосования (тот класс, который набрал больше голосов, идет в финальное предсказание)\n",
    "\n",
    "Вопрос.\n",
    "\n",
    "*Какой accuracy у $C_4$, если известно что классификаторы (базовые алгоритмы) не коррелируют?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Событие когда классификатор $C_1$ угадал правильно обозначим за $P(C_1)$.\n",
    "\n",
    "Тогда $P(C_1) = 0.7$. Аналогично $P(C_2) = 0.7, P(C_3) = 0.7$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим полную группу событий.\n",
    "\n",
    "1. Все 3 классификатра угадали ответ правильно. - Событие X\n",
    "2. 1 угадал правильно, 2 угадали неправильно. - Событие Y \n",
    "3. 2 угадали правильно, 1 угадал неправильно. -Событие Z \n",
    "4. Все 3 классификатора угадали неправильно. - Событие K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $P(X) = 0.7 * 0.7 * 0.7$\n",
    "2. $P(Y) = 0.7 * 0.3 * 0.3$\n",
    "3. $P(Z) = 0.7 * 0.7 * 0.3$\n",
    "4. $P(K) = 0.3 * 0.3 * 0.3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7839999999999998"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.7*0.7*0.7 + 3*0.3*0.7*0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь возьмем 23 классификатора с такой же точностью $0.7$.\n",
    "\n",
    "Чему будет равна итоговая точность $C_{24}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "def compute_ensemble_accuracy(n, accuracy):\n",
    "    probability = 0\n",
    "    edge = int(np.ceil(n / 2))\n",
    "    clfs = [accuracy]*n\n",
    "    for i in range(edge, n + 1):\n",
    "        permuted_clfs = len(list(it.combinations(clfs, i)))\n",
    "        probability_i = permuted_clfs * (accuracy ** i) * ( (1 - accuracy) ** (n - i))\n",
    "        print ('Permutations: {}, Right: {}, Wrong: {}, Probability: {}'.format(permuted_clfs, i, n - i,  probability_i))\n",
    "        probability += permuted_clfs * (accuracy ** i) * ( (1 - accuracy) ** (n - i) )\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutations: 1352078, Right: 12, Wrong: 11, Probability: 0.03315217516646879\n",
      "Permutations: 1144066, Right: 13, Wrong: 10, Probability: 0.06545429455943835\n",
      "Permutations: 817190, Right: 14, Wrong: 9, Probability: 0.10909049093239724\n",
      "Permutations: 490314, Right: 15, Wrong: 8, Probability: 0.15272668730535607\n",
      "Permutations: 245157, Right: 16, Wrong: 7, Probability: 0.17818113518958206\n",
      "Permutations: 100947, Right: 17, Wrong: 6, Probability: 0.1711936396919514\n",
      "Permutations: 33649, Right: 18, Wrong: 5, Probability: 0.13315060864929545\n",
      "Permutations: 8855, Right: 19, Wrong: 4, Probability: 0.0817591456618481\n",
      "Permutations: 1771, Right: 20, Wrong: 3, Probability: 0.0381542679755291\n",
      "Permutations: 253, Right: 21, Wrong: 2, Probability: 0.012718089325176363\n",
      "Permutations: 23, Right: 22, Wrong: 1, Probability: 0.0026977765235222584\n",
      "Permutations: 1, Right: 23, Wrong: 0, Probability: 0.0002736874734008088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.978551998453966"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_ensemble_accuracy(23, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом мы получаем Accuracy = 0.931."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также этот эффект называется \"мудростью толпы\".\n",
    "\n",
    "Теорема Кондорсе, парадокс выбора."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стэкинг своими руками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стэкинг делается следующим образом: берется несколько алгоритмов(случайный лес, линейная регрессия, решающее дерево) и обучается на обучающей выборке. Далее прогнозы этих алгоритмов подаются на вход другого алгоритма(случайный лес, линейная регрессия, решающее дерево), делается предсказание и ответы этого другого алгоритма подаются на вход еще одного алгоритма(и так можно делать до бесконечности).\n",
    "Однако есть очень сильный шанс переобучиться.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся статьей Александра Дьяконова: https://alexanderdyakonov.wordpress.com/2017/03/10/c%D1%82%D0%B5%D0%BA%D0%B8%D0%BD%D0%B3-stacking-%D0%B8-%D0%B1%D0%BB%D0%B5%D0%BD%D0%B4%D0%B8%D0%BD%D0%B3-blending/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='stacking-2b.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_matches = pd.read_csv('train.csv')\n",
    "test_matches = pd.read_csv('test.csv')\n",
    "train = train_matches.copy()\n",
    "train = train.drop('radiant_won', axis=1)\n",
    "test = test_matches.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heroes = pd.read_csv('heroes.csv')\n",
    "heroes_list = ['player_{}'.format(i) for i in range(10)]\n",
    "\n",
    "train = pd.merge(train, heroes, on='mid', how='left')\n",
    "test = pd.merge(test, heroes, on='mid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "player_0    111\n",
       "player_1    110\n",
       "player_2    111\n",
       "player_3    111\n",
       "player_4    111\n",
       "player_5    111\n",
       "player_6    111\n",
       "player_7    111\n",
       "player_8    111\n",
       "player_9    111\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[heroes_list].apply(lambda x: x.unique().shape[0], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "player_0    111\n",
       "player_1    111\n",
       "player_2    111\n",
       "player_3    110\n",
       "player_4    111\n",
       "player_5    110\n",
       "player_6    110\n",
       "player_7    111\n",
       "player_8    111\n",
       "player_9    111\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[heroes_list].apply(lambda x: x.unique().shape[0], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Misha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "keys = np.unique(train[heroes_list[1:]].values)\n",
    "X_pick = np.zeros((train.shape[0], 111))\n",
    "for i, match_id in enumerate(train.index):\n",
    "    for p in range(5):\n",
    "        key = train.ix[match_id, 'player_{}'.format(p)]\n",
    "        X_pick[i, np.where(keys==key)[0][0]] = 1\n",
    "        \n",
    "        key = train.ix[match_id, 'player_{}'.format(p+5)]\n",
    "        X_pick[i, np.where(keys==key)[0][0]] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Misha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "keys = np.unique(test[heroes_list[1:]].values)\n",
    "X_pick_test = np.zeros((test.shape[0], 111))\n",
    "for i, match_id in enumerate(test.index):\n",
    "    for p in range(5):\n",
    "        key = test.ix[match_id, 'player_{}'.format(p)]\n",
    "        X_pick_test[i, np.where(keys==key)[0][0]] = 1\n",
    "        \n",
    "        key = test.ix[match_id, 'player_{}'.format(p+5)]\n",
    "        X_pick_test[i, np.where(keys==key)[0][0]] = -1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.drop(heroes_list, axis=1)\n",
    "test = test.drop(heroes_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features_by_time(data, timestamp, name, filter_list=None):\n",
    "    new_data = data[data.times==timestamp]\n",
    "    new_data = new_data.drop('times', axis = 1)\n",
    "    \n",
    "    radiant_data = new_data[['player_0', 'player_1', 'player_2', 'player_3', 'player_4']].sum(axis=1)\n",
    "    dire_data = new_data[['player_5', 'player_6', 'player_7', 'player_8', 'player_9']].sum(axis=1)\n",
    "    \n",
    "    radiant_data_mean = new_data[['player_0', 'player_1', 'player_2', 'player_3', 'player_4']].mean(axis=1)\n",
    "    dire_data_mean = new_data[['player_5', 'player_6', 'player_7', 'player_8', 'player_9']].mean(axis=1)\n",
    "    \n",
    "    radiant_data_std = new_data[['player_0', 'player_1', 'player_2', 'player_3', 'player_4']].std(axis=1)\n",
    "    dire_data_std = new_data[['player_5', 'player_6', 'player_7', 'player_8', 'player_9']].std(axis=1)\n",
    "    \n",
    "    new_data['radiant_data'] = radiant_data\n",
    "    new_data['dire_data'] = dire_data\n",
    "    \n",
    "    new_data['radiant_data_mean'] = radiant_data_mean\n",
    "    new_data['dire_data_mean'] = dire_data_mean\n",
    "    \n",
    "    new_data['radiant_data_std'] = radiant_data_std\n",
    "    new_data['dire_data_std'] = dire_data_std\n",
    "    \n",
    "    new_data['diff_data'] = new_data['radiant_data'] - new_data['dire_data']\n",
    "    new_data['ratio_data'] = new_data['radiant_data'] / new_data['dire_data']\n",
    "    \n",
    "    new_data['diff_data_mean'] = new_data['radiant_data_mean'] - new_data['dire_data_mean']\n",
    "    new_data['diff_data_std'] = new_data['radiant_data_std'] - new_data['dire_data_std']\n",
    "    \n",
    "    new_data.rename(columns=lambda x: x + '_'+str(name), inplace=True)\n",
    "    new_data.rename(columns={'mid'+'_'+str(name):'mid'}, inplace=True)\n",
    "    \n",
    "    if (filter_list==None):\n",
    "        return new_data\n",
    "    filter_list = [x + '_'+str(name) if x !='mid' else x for x in filter_list ]\n",
    "    return new_data[filter_list]\n",
    "\n",
    "def merge_features(data, features):\n",
    "    return pd.merge(data, features, on='mid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filterNone = None\n",
    "filter1 = ['radiant_data','dire_data','diff_data','ratio_data','mid']\n",
    "filter2 = ['radiant_data','mid']\n",
    "filter3 = ['diff_data','ratio_data','mid']\n",
    "filter4 = ['ratio_data','mid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gold = pd.read_csv('gold.csv')\n",
    "lh = pd.read_csv('lh.csv')\n",
    "xp = pd.read_csv('xp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "active_filter = filterNone\n",
    "timesstamps = [600]#[60,120,180,240,300,360,420,480,540,600]\n",
    "for t in timesstamps:    \n",
    "    gold_features = get_features_by_time(gold, t, 'gold', active_filter)\n",
    "    lh_features = get_features_by_time(lh, t, 'lh', active_filter)\n",
    "    xp_features = get_features_by_time(xp, t, 'xp', active_filter)\n",
    "    \n",
    "    train = merge_features(train, gold_features)\n",
    "    train = merge_features(train, lh_features)\n",
    "    train = merge_features(train, xp_features)\n",
    "    \n",
    "    test = merge_features(test, gold_features)\n",
    "    test = merge_features(test, lh_features)\n",
    "    test = merge_features(test, xp_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timesstamps = [60,120,180,240,300,360,420,480,540,600]\n",
    "for t in timesstamps:    \n",
    "    gold_features = get_features_by_time(gold, t, 'gold', ['radiant_data','dire_data','mid'])\n",
    "    \n",
    "    gold_features.rename(columns=lambda x: x + '_'+str(t), inplace=True)\n",
    "    gold_features.rename(columns={'mid'+'_'+str(t):'mid'}, inplace=True)\n",
    "    \n",
    "    train = merge_features(train, gold_features)\n",
    "    test = merge_features(test, gold_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>player_0_gold</th>\n",
       "      <th>player_1_gold</th>\n",
       "      <th>player_2_gold</th>\n",
       "      <th>player_3_gold</th>\n",
       "      <th>player_4_gold</th>\n",
       "      <th>player_5_gold</th>\n",
       "      <th>player_6_gold</th>\n",
       "      <th>player_7_gold</th>\n",
       "      <th>player_8_gold</th>\n",
       "      <th>...</th>\n",
       "      <th>radiant_data_gold_360</th>\n",
       "      <th>dire_data_gold_360</th>\n",
       "      <th>radiant_data_gold_420</th>\n",
       "      <th>dire_data_gold_420</th>\n",
       "      <th>radiant_data_gold_480</th>\n",
       "      <th>dire_data_gold_480</th>\n",
       "      <th>radiant_data_gold_540</th>\n",
       "      <th>dire_data_gold_540</th>\n",
       "      <th>radiant_data_gold_600</th>\n",
       "      <th>dire_data_gold_600</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3454</td>\n",
       "      <td>5206</td>\n",
       "      <td>2613</td>\n",
       "      <td>4426</td>\n",
       "      <td>5755</td>\n",
       "      <td>4072</td>\n",
       "      <td>3997</td>\n",
       "      <td>5917</td>\n",
       "      <td>1725</td>\n",
       "      <td>...</td>\n",
       "      <td>11627</td>\n",
       "      <td>13323</td>\n",
       "      <td>13499</td>\n",
       "      <td>15333</td>\n",
       "      <td>17209</td>\n",
       "      <td>17605</td>\n",
       "      <td>19653</td>\n",
       "      <td>19787</td>\n",
       "      <td>21454</td>\n",
       "      <td>22095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2477</td>\n",
       "      <td>5760</td>\n",
       "      <td>3816</td>\n",
       "      <td>4353</td>\n",
       "      <td>5759</td>\n",
       "      <td>7659</td>\n",
       "      <td>5066</td>\n",
       "      <td>2748</td>\n",
       "      <td>4440</td>\n",
       "      <td>...</td>\n",
       "      <td>12234</td>\n",
       "      <td>13640</td>\n",
       "      <td>14879</td>\n",
       "      <td>16494</td>\n",
       "      <td>17669</td>\n",
       "      <td>18691</td>\n",
       "      <td>20039</td>\n",
       "      <td>21734</td>\n",
       "      <td>22165</td>\n",
       "      <td>24536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3604</td>\n",
       "      <td>1948</td>\n",
       "      <td>8581</td>\n",
       "      <td>4390</td>\n",
       "      <td>2869</td>\n",
       "      <td>3096</td>\n",
       "      <td>2301</td>\n",
       "      <td>5130</td>\n",
       "      <td>2530</td>\n",
       "      <td>...</td>\n",
       "      <td>12418</td>\n",
       "      <td>9386</td>\n",
       "      <td>14482</td>\n",
       "      <td>10755</td>\n",
       "      <td>16601</td>\n",
       "      <td>12156</td>\n",
       "      <td>18428</td>\n",
       "      <td>14495</td>\n",
       "      <td>21392</td>\n",
       "      <td>15548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3675</td>\n",
       "      <td>4103</td>\n",
       "      <td>5154</td>\n",
       "      <td>3030</td>\n",
       "      <td>2076</td>\n",
       "      <td>3920</td>\n",
       "      <td>3494</td>\n",
       "      <td>3392</td>\n",
       "      <td>4458</td>\n",
       "      <td>...</td>\n",
       "      <td>9645</td>\n",
       "      <td>11517</td>\n",
       "      <td>11999</td>\n",
       "      <td>12680</td>\n",
       "      <td>13822</td>\n",
       "      <td>14971</td>\n",
       "      <td>15713</td>\n",
       "      <td>16665</td>\n",
       "      <td>18038</td>\n",
       "      <td>17484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4252</td>\n",
       "      <td>2412</td>\n",
       "      <td>2545</td>\n",
       "      <td>4264</td>\n",
       "      <td>2544</td>\n",
       "      <td>4752</td>\n",
       "      <td>5389</td>\n",
       "      <td>4954</td>\n",
       "      <td>3954</td>\n",
       "      <td>...</td>\n",
       "      <td>9513</td>\n",
       "      <td>11903</td>\n",
       "      <td>11434</td>\n",
       "      <td>14350</td>\n",
       "      <td>12643</td>\n",
       "      <td>16134</td>\n",
       "      <td>14361</td>\n",
       "      <td>19035</td>\n",
       "      <td>16017</td>\n",
       "      <td>22041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mid  player_0_gold  player_1_gold  player_2_gold  player_3_gold  \\\n",
       "0    0           3454           5206           2613           4426   \n",
       "1    1           2477           5760           3816           4353   \n",
       "2    2           3604           1948           8581           4390   \n",
       "3    4           3675           4103           5154           3030   \n",
       "4    5           4252           2412           2545           4264   \n",
       "\n",
       "   player_4_gold  player_5_gold  player_6_gold  player_7_gold  player_8_gold  \\\n",
       "0           5755           4072           3997           5917           1725   \n",
       "1           5759           7659           5066           2748           4440   \n",
       "2           2869           3096           2301           5130           2530   \n",
       "3           2076           3920           3494           3392           4458   \n",
       "4           2544           4752           5389           4954           3954   \n",
       "\n",
       "          ...          radiant_data_gold_360  dire_data_gold_360  \\\n",
       "0         ...                          11627               13323   \n",
       "1         ...                          12234               13640   \n",
       "2         ...                          12418                9386   \n",
       "3         ...                           9645               11517   \n",
       "4         ...                           9513               11903   \n",
       "\n",
       "   radiant_data_gold_420  dire_data_gold_420  radiant_data_gold_480  \\\n",
       "0                  13499               15333                  17209   \n",
       "1                  14879               16494                  17669   \n",
       "2                  14482               10755                  16601   \n",
       "3                  11999               12680                  13822   \n",
       "4                  11434               14350                  12643   \n",
       "\n",
       "   dire_data_gold_480  radiant_data_gold_540  dire_data_gold_540  \\\n",
       "0               17605                  19653               19787   \n",
       "1               18691                  20039               21734   \n",
       "2               12156                  18428               14495   \n",
       "3               14971                  15713               16665   \n",
       "4               16134                  14361               19035   \n",
       "\n",
       "   radiant_data_gold_600  dire_data_gold_600  \n",
       "0                  21454               22095  \n",
       "1                  22165               24536  \n",
       "2                  21392               15548  \n",
       "3                  18038               17484  \n",
       "4                  16017               22041  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "radiant_diff = ['radiant_data_gold_60','radiant_data_gold_120','radiant_data_gold_180','radiant_data_gold_240','radiant_data_gold_300','radiant_data_gold_360','radiant_data_gold_420','radiant_data_gold_480','radiant_data_gold_540','radiant_data_gold_600']\n",
    "radiant_data = np.gradient(train[radiant_diff],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dire_diff = ['dire_data_gold_60','dire_data_gold_120','dire_data_gold_180','dire_data_gold_240','dire_data_gold_300','dire_data_gold_360','dire_data_gold_420','dire_data_gold_480','dire_data_gold_540','dire_data_gold_600']\n",
    "dire_data = np.gradient(train[dire_diff],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.drop(radiant_diff,axis=1)\n",
    "train = train.drop(dire_diff,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sort_quantity_feature(data, ls1, ls2, drop=False):\n",
    "    new_ls1 = [x+str('_sorted') for x in ls1]\n",
    "    new_ls2 = [x+str('_sorted') for x in ls2]\n",
    "    \n",
    "    for match_id in data.index:\n",
    "        key = data.loc[match_id]\n",
    "        s = sorted(key[ls1])\n",
    "        for i, el in enumerate(s):\n",
    "            data.loc[match_id,new_ls1[i]] = s[i]\n",
    "            \n",
    "        s = sorted(key[ls2])\n",
    "        for i, el in enumerate(s):\n",
    "            data.loc[match_id,new_ls2[i]] = s[i]\n",
    "    if drop:\n",
    "        data = data.drop(ls1,axis=1)\n",
    "        data = data.drop(ls2,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_full = pd.read_csv('train10.csv')\n",
    "train_full = train_full.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>radiant_data_gold</th>\n",
       "      <th>dire_data_gold</th>\n",
       "      <th>diff_data_gold</th>\n",
       "      <th>ratio_data_gold</th>\n",
       "      <th>radiant_data_lh</th>\n",
       "      <th>dire_data_lh</th>\n",
       "      <th>diff_data_lh</th>\n",
       "      <th>ratio_data_lh</th>\n",
       "      <th>radiant_data_xp</th>\n",
       "      <th>...</th>\n",
       "      <th>item_111</th>\n",
       "      <th>item_112</th>\n",
       "      <th>item_113</th>\n",
       "      <th>item_114</th>\n",
       "      <th>item_115</th>\n",
       "      <th>item_116</th>\n",
       "      <th>item_117</th>\n",
       "      <th>item_118</th>\n",
       "      <th>item_119</th>\n",
       "      <th>item_120</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21454</td>\n",
       "      <td>22095</td>\n",
       "      <td>-641</td>\n",
       "      <td>0.970989</td>\n",
       "      <td>148</td>\n",
       "      <td>192</td>\n",
       "      <td>-44</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>15856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22165</td>\n",
       "      <td>24536</td>\n",
       "      <td>-2371</td>\n",
       "      <td>0.903366</td>\n",
       "      <td>157</td>\n",
       "      <td>144</td>\n",
       "      <td>13</td>\n",
       "      <td>1.090278</td>\n",
       "      <td>15231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>21392</td>\n",
       "      <td>15548</td>\n",
       "      <td>5844</td>\n",
       "      <td>1.375868</td>\n",
       "      <td>174</td>\n",
       "      <td>99</td>\n",
       "      <td>75</td>\n",
       "      <td>1.757576</td>\n",
       "      <td>18003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>18038</td>\n",
       "      <td>17484</td>\n",
       "      <td>554</td>\n",
       "      <td>1.031686</td>\n",
       "      <td>143</td>\n",
       "      <td>101</td>\n",
       "      <td>42</td>\n",
       "      <td>1.415842</td>\n",
       "      <td>15334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>16017</td>\n",
       "      <td>22041</td>\n",
       "      <td>-6024</td>\n",
       "      <td>0.726691</td>\n",
       "      <td>96</td>\n",
       "      <td>145</td>\n",
       "      <td>-49</td>\n",
       "      <td>0.662069</td>\n",
       "      <td>11391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mid  radiant_data_gold  dire_data_gold  diff_data_gold  ratio_data_gold  \\\n",
       "0    0              21454           22095            -641         0.970989   \n",
       "1    1              22165           24536           -2371         0.903366   \n",
       "2    2              21392           15548            5844         1.375868   \n",
       "3    4              18038           17484             554         1.031686   \n",
       "4    5              16017           22041           -6024         0.726691   \n",
       "\n",
       "   radiant_data_lh  dire_data_lh  diff_data_lh  ratio_data_lh  \\\n",
       "0              148           192           -44       0.770833   \n",
       "1              157           144            13       1.090278   \n",
       "2              174            99            75       1.757576   \n",
       "3              143           101            42       1.415842   \n",
       "4               96           145           -49       0.662069   \n",
       "\n",
       "   radiant_data_xp    ...     item_111  item_112  item_113  item_114  \\\n",
       "0            15856    ...          0.0       0.0       0.0       0.0   \n",
       "1            15231    ...          0.0      -1.0       0.0       0.0   \n",
       "2            18003    ...          0.0       0.0      -1.0       0.0   \n",
       "3            15334    ...          0.0       0.0       0.0       0.0   \n",
       "4            11391    ...          0.0       1.0      -1.0       0.0   \n",
       "\n",
       "   item_115  item_116  item_117  item_118  item_119  item_120  \n",
       "0      -1.0       0.0       0.0       0.0       0.0       0.0  \n",
       "1      -2.0       0.0       0.0       0.0       0.0       0.0  \n",
       "2       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "3       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "4      -2.0       0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 164 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = train_full.values\n",
    "y_train = train_matches.radiant_won.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.70540149  0.70617726  0.69778468  0.69231158  0.69818708]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.69997241968521795"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "ls = cross_val_score(clf2, x_train, y_train, cv=5, scoring='roc_auc')\n",
    "print(ls)\n",
    "np.mean(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfs = [RandomForestClassifier(n_estimators=100, n_jobs=-1),\n",
    "        LogisticRegression(C=1000,class_weight=None,tol=1e-05, n_jobs=-1, penalty='l2'),\n",
    "        LogisticRegression(C=1000,class_weight=None,tol=1e-05, n_jobs=-1, penalty='l1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_blend_train = np.zeros((x_train.shape[0], len(clfs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "1 LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=1e-05,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Misha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=1e-05,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Misha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    }
   ],
   "source": [
    "for j, clf in enumerate(clfs):\n",
    "    print (j, clf)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_submission = clf.predict_proba(x_train)[:, 1]\n",
    "    dataset_blend_train[:, j] = y_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.79      ,  0.62541628,  0.63116392],\n",
       "       [ 0.19      ,  0.41167685,  0.4299593 ],\n",
       "       [ 0.92      ,  0.86243693,  0.8663499 ],\n",
       "       ..., \n",
       "       [ 0.84      ,  0.29107294,  0.29296397],\n",
       "       [ 0.2       ,  0.52584289,  0.52574765],\n",
       "       [ 0.12      ,  0.17203933,  0.17056315]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_blend_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Misha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\Users\\Misha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\Users\\Misha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\Users\\Misha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\Users\\Misha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=100,class_weight=None,tol=1e-05, random_state=1234, n_jobs=-1)\n",
    "ls = cross_val_score(clf2, dataset_blend_train, y_train, cv=5, scoring='roc_auc')\n",
    "print(ls)\n",
    "np.mean(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "1 LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=1e-05,\n",
      "          verbose=0, warm_start=False)\n",
      "Fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Misha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "2 LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=1e-05,\n",
      "          verbose=0, warm_start=False)\n",
      "Fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Misha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5,shuffle=False)\n",
    "for j, clf in enumerate(clfs):\n",
    "    print (j, clf)\n",
    "    for i, (train_, test_) in enumerate(kf.split(x_train, y_train)):\n",
    "        print (\"Fold\", i)\n",
    "        X_tr = x_train[train_]\n",
    "        y_tr = y_train[train_]\n",
    "        X_te = x_train[test_]\n",
    "        y_te = y_train[test_]\n",
    "        clf.fit(X_tr, y_tr)\n",
    "        y_submission = clf.predict_proba(X_te)[:, 1]\n",
    "        dataset_blend_train[test_, j] = y_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.54      ,  0.60015406,  0.61506819],\n",
       "       [ 0.4       ,  0.45835682,  0.4848695 ],\n",
       "       [ 0.57      ,  0.86152048,  0.86655162],\n",
       "       ..., \n",
       "       [ 0.49      ,  0.26021496,  0.26707557],\n",
       "       [ 0.5       ,  0.52159219,  0.5195483 ],\n",
       "       [ 0.26      ,  0.16977267,  0.16895052]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_blend_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.70338126  0.70572479  0.69920753  0.69357057  0.70512031]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.70140089238096515"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "ls = cross_val_score(clf2, x_train, y_train, cv=5, scoring='roc_auc')\n",
    "print(ls)\n",
    "np.mean(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.71859377  0.71797816  0.71348507  0.70361561  0.71252682]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Misha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\Users\\Misha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\Users\\Misha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\Users\\Misha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\Users\\Misha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.71323988646047964"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=100,class_weight=None,tol=1e-05, random_state=1234, n_jobs=-1)\n",
    "ls = cross_val_score(clf2, dataset_blend_train, y_train, cv=5, scoring='roc_auc')\n",
    "print(ls)\n",
    "np.mean(ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Блэндинг своими руками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Блэндинг - это стекинг с количеством фолдов=2. Очень часто используется когда нет достаточно времени, чтобы делать полынй стекинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='stacking-2b.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бэггинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
